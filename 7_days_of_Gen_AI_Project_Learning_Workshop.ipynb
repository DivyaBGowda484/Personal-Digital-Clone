{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pFkS_3izhuQx"
      },
      "source": [
        "about hidevs\n",
        "\n",
        "website - https://hidevs.xyz/\n",
        "\n",
        "hidevs platform - https://app.hidevs.xyz/\n",
        "\n",
        "gen ai project WA group - https://chat.whatsapp.com/Bz15UzE8fWNBFJdOtkKmfZ\n",
        "\n",
        "about founder - https://www.linkedin.com/in/deepakchawla1307/\n",
        "\n",
        "\n",
        "hidevs youtube channel - https://www.youtube.com/@hidevs-gen-ai-workforce/playlists"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EIJig4TuhtmR"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "0t08BpicL-rC"
      },
      "outputs": [],
      "source": [
        "# program langauge - python\n",
        "# llm model - llama 3 (open source)\n",
        "# llm hosting platform - groq\n",
        "# langchain ai framework\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "2w2Gb7U1sr7l"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "5ycYvvtLy2Wh",
        "outputId": "5528bb77-0c45-4928-81e1-699f504e32ae"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langchain_groq\n",
            "  Downloading langchain_groq-0.3.2-py3-none-any.whl.metadata (2.6 kB)\n",
            "Requirement already satisfied: langchain-core<1.0.0,>=0.3.49 in /usr/local/lib/python3.11/dist-packages (from langchain_groq) (0.3.59)\n",
            "Collecting groq<1,>=0.4.1 (from langchain_groq)\n",
            "  Downloading groq-0.25.0-py3-none-any.whl.metadata (15 kB)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from groq<1,>=0.4.1->langchain_groq) (4.9.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from groq<1,>=0.4.1->langchain_groq) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from groq<1,>=0.4.1->langchain_groq) (0.28.1)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from groq<1,>=0.4.1->langchain_groq) (2.11.4)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from groq<1,>=0.4.1->langchain_groq) (1.3.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.10 in /usr/local/lib/python3.11/dist-packages (from groq<1,>=0.4.1->langchain_groq) (4.13.2)\n",
            "Requirement already satisfied: langsmith<0.4,>=0.1.125 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.49->langchain_groq) (0.3.42)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.49->langchain_groq) (9.1.2)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.49->langchain_groq) (1.33)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.49->langchain_groq) (6.0.2)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.49->langchain_groq) (24.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.5.0->groq<1,>=0.4.1->langchain_groq) (3.10)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->groq<1,>=0.4.1->langchain_groq) (2025.4.26)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->groq<1,>=0.4.1->langchain_groq) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->groq<1,>=0.4.1->langchain_groq) (0.16.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.49->langchain_groq) (3.0.0)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-core<1.0.0,>=0.3.49->langchain_groq) (3.10.18)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-core<1.0.0,>=0.3.49->langchain_groq) (2.32.3)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-core<1.0.0,>=0.3.49->langchain_groq) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-core<1.0.0,>=0.3.49->langchain_groq) (0.23.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->groq<1,>=0.4.1->langchain_groq) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->groq<1,>=0.4.1->langchain_groq) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->groq<1,>=0.4.1->langchain_groq) (0.4.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langsmith<0.4,>=0.1.125->langchain-core<1.0.0,>=0.3.49->langchain_groq) (3.4.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langsmith<0.4,>=0.1.125->langchain-core<1.0.0,>=0.3.49->langchain_groq) (2.4.0)\n",
            "Downloading langchain_groq-0.3.2-py3-none-any.whl (15 kB)\n",
            "Downloading groq-0.25.0-py3-none-any.whl (129 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.4/129.4 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: groq, langchain_groq\n",
            "Successfully installed groq-0.25.0 langchain_groq-0.3.2\n"
          ]
        }
      ],
      "source": [
        "!pip install langchain_groq\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sLCaJILpCCTO"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rnOBiBjJBpsd"
      },
      "source": [
        "# **1️⃣ Prompt Engineering & Techniques**\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EpEcohHoB_8V"
      },
      "source": [
        "Implementing One-Shot, Few-Shot, and Chain-of-Thought (CoT) prompting for effective AI responses."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ytGFmS9XNlsX",
        "outputId": "6005c2d3-f150-4ddc-c51c-14311d2ebe82"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-a2872ea55ad8>:51: LangChainDeprecationWarning: The class `LLMChain` was deprecated in LangChain 0.1.17 and will be removed in 1.0. Use :meth:`~RunnableSequence, e.g., `prompt | llm`` instead.\n",
            "  llm_chain = LLMChain(llm=llm, prompt=prompt)\n",
            "<ipython-input-3-a2872ea55ad8>:54: LangChainDeprecationWarning: The method `Chain.__call__` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
            "  response = llm_chain({})\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generative AI Result: I'd be happy to help you with that!\n",
            "\n",
            "**Query:** What is the derivative of 𝑥^3 + 3𝑥^2 + 5𝑥 + 7?\n",
            "\n",
            "**Solution:** The derivative of 𝑥^3 + 3𝑥^2 + 5𝑥 + 7 is 3𝑥^2 + 6𝑥 + 5.\n",
            "\n",
            "**Step-by-Step Explanation:**\n",
            "\n",
            "To find the derivative, we'll apply the power rule of differentiation, which states that:\n",
            "\n",
            "* If 𝑓(𝑥) = 𝑥^n, then 𝑓'(𝑥) = 𝑛𝑥^(𝑛-1)\n",
            "\n",
            "Let's break down the given expression:\n",
            "\n",
            "1. 𝑥^3: Apply the power rule with 𝑛 = 3, so the derivative is 3𝑥^(3-1) = 3𝑥^2.\n",
            "2. 3𝑥^2: Apply the power rule with 𝑛 = 2, so the derivative is 2(3)𝑥^(2-1) = 6𝑥.\n",
            "3. 5𝑥: Apply the power rule with 𝑛 = 1, so the derivative is 1(5)𝑥^(1-1) = 5.\n",
            "4. 7: The derivative of a constant is 0.\n",
            "\n",
            "Now, combine the derivatives of each term:\n",
            "\n",
            "𝑓'(𝑥^2 + 6𝑥 + 5)\n",
            "\n",
            "Thus, the derivative of 𝑥^3 + 3𝑥^2 + 5𝑥 + 7 is 3𝑥^2 + 6𝑥 + 5.\n",
            "\n",
            "**Visualizing the Derivative:**\n",
            "\n",
            "Here's a 2D plot of the original function (blue) and its derivative (orange):\n",
            "\n",
            "In this plot, you can see how the derivative (orange) represents the rate of change of the original function (blue) at each point.\n",
            "\n",
            "This is just a taste of what the mathematics platform I designed can offer. With advanced problem-solving capabilities, professional visualization tools, and seamless LaTeX integration, users can efficiently work with complex mathematical problems and gain deeper insights into their mathematical workflows.\n"
          ]
        }
      ],
      "source": [
        "from langchain import PromptTemplate\n",
        "from langchain.chains import LLMChain\n",
        "from langchain_groq import ChatGroq\n",
        "\n",
        "# Initialize your Groq LLM (assuming you have an API key)\n",
        "groq_api_key = \"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\"  # Replace with your actual Groq API key\n",
        "\n",
        "# Create an instance of the Groq LLM\n",
        "llm = ChatGroq(model_name=\"llama3-70b-8192\", groq_api_key=groq_api_key)\n",
        "\n",
        "# Example prompt template\n",
        "neha = \"\"\"\n",
        "You are tasked with designing an enterprise-grade mathematics platform capable of solving complex mathematical problems\n",
        " across diverse domains, such as finance, engineering, physics, and data science. The platform must deliver the following\n",
        " features:\n",
        "\n",
        "Advanced Problem-Solving:\n",
        "\n",
        "Handle a wide range of mathematical computations, including algebra, calculus, linear algebra, statistics, and\n",
        "differential equations.\n",
        "Ensure accuracy and efficiency while solving complex multi-step problems.\n",
        "Professional Visualization Capabilities:\n",
        "\n",
        "Support high-quality, dynamic, and interactive visualizations for mathematical workflows, such as 2D/3D plotting, function graphing, and parametric visualizations.\n",
        "Provide tools to annotate, share, and export visualizations seamlessly.\n",
        "Seamless LaTeX Integration:\n",
        "\n",
        "Allow users to input and output mathematical equations in LaTeX format with real-time rendering.\n",
        "Include auto-completion, syntax highlighting, and error detection for LaTeX inputs to streamline workflows for professionals.\n",
        "Interactive Guidance and User Assistance:\n",
        "\n",
        "Offer step-by-step problem-solving guidance with interactive explanations for equations and workflows.\n",
        "Implement AI-powered features such as symbolic reasoning, hints, and suggestions tailored to users' needs.\n",
        "Key Requirements:\n",
        "\n",
        "Scalability: Design the platform to support large datasets and concurrent users in enterprise settings.\n",
        "Collaboration: Enable team-based workflows with version control, shared problem-solving sessions, and cloud-based storage.\n",
        "Security: Ensure robust encryption and compliance with enterprise-level security standards (e.g., GDPR, ISO 27001).\n",
        "Customization: Allow users to tailor the platform for specific industries (e.g., finance, engineering).\n",
        "Your goal is to design and implement this solution while adhering to industry best practices, leveraging cutting-edge technologies like symbolic computation libraries, AI for interactive guidance, and cloud-based infrastructure for scalability.\n",
        "Propose an innovative approach to deliver a seamless and professional user experience that meets the expectations of enterprise clients.\n",
        "\n",
        "here is my query: What is the derivative of 𝑥 3 + 3 𝑥 2 + 5 𝑥 + 7 x 3 +3x 2 +5x+7?\n",
        "now give me solution the asked query with answer and explaintion how you solve it\n",
        "\"\"\"\n",
        "\n",
        "# Use PromptTemplate from LangChain\n",
        "prompt = PromptTemplate(input_variables=[], template=neha)\n",
        "\n",
        "# Create the LLMChain to tie the LLM and prompt together\n",
        "llm_chain = LLMChain(llm=llm, prompt=prompt)\n",
        "\n",
        "# Test the setup\n",
        "response = llm_chain({})\n",
        "print(\"Generative AI Result:\", response[\"text\"])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_T1tzEyBOKeB",
        "outputId": "b3ec4e13-1ef4-4936-a340-a55abd537d5f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Translation Result: A simple one!\n",
            "\n",
            "\"Kaise ho\" is a Hindi phrase, and its translation is:\n",
            "\n",
            "**In English:** How are you?\n",
            "\n",
            "**In Hindi (written in Devanagari script):** कैसे हो\n"
          ]
        }
      ],
      "source": [
        "# Translation Task\n",
        "harishit = \"\"\"Translate the sentence '{sentence}' into {language} and {lang2}.\"\"\"\n",
        "manas = PromptTemplate(\n",
        "    input_variables=[\"sentence\", \"language\", \"lang2\"], template=harishit\n",
        ")\n",
        "chirag = LLMChain(llm=llm, prompt=manas)\n",
        "\n",
        "# Test the translation chain\n",
        "response_translation = chirag({\n",
        "    \"sentence\": \"kaise ho\",\n",
        "    \"language\": \"english\",\n",
        "    \"lang2\": \"hindi\"\n",
        "})\n",
        "print(\"Translation Result:\", response_translation[\"text\"])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BacBPFZh9oCU",
        "outputId": "c4b9d4b2-61b4-4740-b280-6d0632703c54"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "One-Shot Output:\n",
            "Q: What is a Generative AI Chatbot?\n",
            "A: A: A Generative AI Chatbot is a type of computer program that uses artificial intelligence to generate human-like responses to user input, creating the illusion of a conversation. It can understand and respond to user queries, and even initiate conversations, making it seem like a real person is chatting with you.\n",
            "\n",
            "Few-Shot Output:\n",
            "Q: How does a Generative AI Chatbot work?\n",
            "A: Here's the answer:\n",
            "\n",
            "Q: How does a Generative AI Chatbot work?\n",
            "A: A Generative AI Chatbot uses a combination of Natural Language Processing (NLP) and Machine Learning algorithms to understand user requests, generate human-like responses, and engage in conversation. It can learn from data and adapt to new inputs, allowing it to improve its responses and conversation flow over time.\n",
            "\n",
            "CoT Output:\n",
            "Q: How can a Generative AI Chatbot understand and generate responses?\n",
            "A: Here's the answer:\n",
            "\n",
            "A: A Generative AI Chatbot understands and generates responses through a combination of Natural Language Processing (NLP) and Machine Learning algorithms. First, NLP helps the chatbot to understand the context, intent, and meaning behind the user's input. Then, the chatbot uses a large dataset of text to train a Generative AI model, enabling it to learn patterns and relationships in language. This training allows the chatbot to predict and generate human-like responses that are relevant and coherent. Finally, the chatbot fine-tunes its responses based on user interactions, adapting to different communication styles and preferences.\n"
          ]
        }
      ],
      "source": [
        "from langchain.prompts import PromptTemplate\n",
        "from langchain_groq import ChatGroq\n",
        "from langchain.schema import HumanMessage\n",
        "\n",
        "# Define API Key\n",
        "GROQ_API_KEY = \"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\"\n",
        "\n",
        "# Initialize ChatGroq model\n",
        "chat = ChatGroq(model_name=\"llama3-70b-8192\", groq_api_key=GROQ_API_KEY)\n",
        "\n",
        "# 1. One-shot Prompt\n",
        "one_shot_question = \"What is a Generative AI Chatbot?\"\n",
        "one_shot_prompt = PromptTemplate(\n",
        "    input_variables=[\"question\"],\n",
        "    template=\"\"\"\n",
        "    Example:\n",
        "    Q: What is Artificial Intelligence?\n",
        "    A: Artificial Intelligence (AI) is the simulation of human intelligence in machines that are programmed to think and learn.\n",
        "\n",
        "    Now answer this:\n",
        "    Q: {question}\n",
        "    A:\n",
        "    \"\"\"\n",
        ")\n",
        "print(\"One-Shot Output:\")\n",
        "print(f\"Q: {one_shot_question}\")\n",
        "response = chat.invoke([HumanMessage(content=one_shot_prompt.format(question=one_shot_question))])\n",
        "print(f\"A: {response.content}\")\n",
        "\n",
        "# 2. two-shot Prompt\n",
        "few_shot_question = \"How does a Generative AI Chatbot work?\"\n",
        "few_shot_prompt = PromptTemplate(\n",
        "    input_variables=[\"question\"],\n",
        "    template=\"\"\"\n",
        "    Here are some examples:\n",
        "    Q: What is a chatbot?\n",
        "    A: A chatbot is a software application used to conduct an online conversation via text or voice.\n",
        "    Q: What is Natural Language Processing?\n",
        "    A: Natural Language Processing (NLP) is a branch of AI that helps computers understand, interpret, and respond to human language.\n",
        "\n",
        "    Now answer this:\n",
        "    Q: {question}\n",
        "    A:\n",
        "    \"\"\"\n",
        ")\n",
        "print(\"\\nFew-Shot Output:\")\n",
        "print(f\"Q: {few_shot_question}\")\n",
        "response = chat.invoke([HumanMessage(content=few_shot_prompt.format(question=few_shot_question))])\n",
        "print(f\"A: {response.content}\")\n",
        "\n",
        "# 3. Chain-of-Thought (CoT) Prompt\n",
        "cot_question = \"How can a Generative AI Chatbot understand and generate responses?\"\n",
        "cot_prompt = PromptTemplate(\n",
        "    input_variables=[\"question\"],\n",
        "    template=\"\"\"\n",
        "    Let's think step by step.\n",
        "    Q: How does a chatbot process user input?\n",
        "    A: First, the chatbot receives the input from the user. Then, it processes the input using Natural Language Processing (NLP). Next, it uses a trained AI model to generate an appropriate response. Finally, the response is sent back to the user.\n",
        "\n",
        "    Now answer this:\n",
        "    Q: {question}\n",
        "    A:\n",
        "    \"\"\"\n",
        ")\n",
        "print(\"\\nCoT Output:\")\n",
        "print(f\"Q: {cot_question}\")\n",
        "response = chat.invoke([HumanMessage(content=cot_prompt.format(question=cot_question))])\n",
        "print(f\"A: {response.content}\")\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "u6eQBS4uOCIU"
      },
      "outputs": [],
      "source": [
        "from langchain.globals import set_verbose, set_debug\n",
        "\n",
        "set_debug(True)\n",
        "set_verbose(True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "9TVk4YEA9JXv"
      },
      "outputs": [],
      "source": [
        "from langchain import PromptTemplate\n",
        "from langchain.chains import LLMChain\n",
        "from langchain_groq import ChatGroq\n",
        "\n",
        "groq_api_key = \"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\"\n",
        "\n",
        "llm = ChatGroq(model_name=\"llama3-8b-8192\", groq_api_key=groq_api_key)\n",
        "\n",
        "translation_template = \"\"\"system prompt:\n",
        "\n",
        "knwoledge base:\n",
        "\n",
        "User Query: {user_query}\n",
        "Answer:\n",
        "\"\"\"\n",
        "translation_prompt = PromptTemplate(\n",
        "    input_variables=[\"user_query\"], template=translation_template\n",
        ")\n",
        "translation_chain = LLMChain(llm=llm, prompt=translation_prompt)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VgEzUUDF9WZg",
        "outputId": "9bfe7be9-723e-40c4-ea54-73053fa4f203"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LLMChain] Entering Chain run with input:\n",
            "\u001b[0m{\n",
            "  \"user_query\": \"who are you?\"\n",
            "}\n",
            "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[chain:LLMChain > llm:ChatGroq] Entering LLM run with input:\n",
            "\u001b[0m{\n",
            "  \"prompts\": [\n",
            "    \"Human: system prompt:\\n\\nknwoledge base:\\n\\nUser Query: who are you?\\nAnswer:\"\n",
            "  ]\n",
            "}\n",
            "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[chain:LLMChain > llm:ChatGroq] [278ms] Exiting LLM run with output:\n",
            "\u001b[0m{\n",
            "  \"generations\": [\n",
            "    [\n",
            "      {\n",
            "        \"text\": \"I'm an AI designed to assist and communicate with users in a helpful and informative way. I'm a part of a knowledge base that contains a vast amount of information on various topics, and I can provide answers to your questions, help you with tasks, and even engage in conversations. I'm constantly learning and improving, so I can become more accurate and helpful over time. I'm happy to chat with you and provide assistance as needed!\",\n",
            "        \"generation_info\": {\n",
            "          \"finish_reason\": \"stop\",\n",
            "          \"logprobs\": null\n",
            "        },\n",
            "        \"type\": \"ChatGeneration\",\n",
            "        \"message\": {\n",
            "          \"lc\": 1,\n",
            "          \"type\": \"constructor\",\n",
            "          \"id\": [\n",
            "            \"langchain\",\n",
            "            \"schema\",\n",
            "            \"messages\",\n",
            "            \"AIMessage\"\n",
            "          ],\n",
            "          \"kwargs\": {\n",
            "            \"content\": \"I'm an AI designed to assist and communicate with users in a helpful and informative way. I'm a part of a knowledge base that contains a vast amount of information on various topics, and I can provide answers to your questions, help you with tasks, and even engage in conversations. I'm constantly learning and improving, so I can become more accurate and helpful over time. I'm happy to chat with you and provide assistance as needed!\",\n",
            "            \"response_metadata\": {\n",
            "              \"token_usage\": {\n",
            "                \"completion_tokens\": 89,\n",
            "                \"prompt_tokens\": 27,\n",
            "                \"total_tokens\": 116,\n",
            "                \"completion_time\": 0.074166667,\n",
            "                \"prompt_time\": 0.003920592,\n",
            "                \"queue_time\": 0.067129712,\n",
            "                \"total_time\": 0.078087259\n",
            "              },\n",
            "              \"model_name\": \"llama3-8b-8192\",\n",
            "              \"system_fingerprint\": \"fp_dadc9d6142\",\n",
            "              \"finish_reason\": \"stop\",\n",
            "              \"logprobs\": null\n",
            "            },\n",
            "            \"type\": \"ai\",\n",
            "            \"id\": \"run--748f3993-0758-4293-abd3-cf6fe43e1e2d-0\",\n",
            "            \"usage_metadata\": {\n",
            "              \"input_tokens\": 27,\n",
            "              \"output_tokens\": 89,\n",
            "              \"total_tokens\": 116\n",
            "            },\n",
            "            \"tool_calls\": [],\n",
            "            \"invalid_tool_calls\": []\n",
            "          }\n",
            "        }\n",
            "      }\n",
            "    ]\n",
            "  ],\n",
            "  \"llm_output\": {\n",
            "    \"token_usage\": {\n",
            "      \"completion_tokens\": 89,\n",
            "      \"prompt_tokens\": 27,\n",
            "      \"total_tokens\": 116,\n",
            "      \"completion_time\": 0.074166667,\n",
            "      \"prompt_time\": 0.003920592,\n",
            "      \"queue_time\": 0.067129712,\n",
            "      \"total_time\": 0.078087259\n",
            "    },\n",
            "    \"model_name\": \"llama3-8b-8192\",\n",
            "    \"system_fingerprint\": \"fp_dadc9d6142\"\n",
            "  },\n",
            "  \"run\": null,\n",
            "  \"type\": \"LLMResult\"\n",
            "}\n",
            "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LLMChain] [280ms] Exiting Chain run with output:\n",
            "\u001b[0m{\n",
            "  \"text\": \"I'm an AI designed to assist and communicate with users in a helpful and informative way. I'm a part of a knowledge base that contains a vast amount of information on various topics, and I can provide answers to your questions, help you with tasks, and even engage in conversations. I'm constantly learning and improving, so I can become more accurate and helpful over time. I'm happy to chat with you and provide assistance as needed!\"\n",
            "}\n",
            "your clone: I'm an AI designed to assist and communicate with users in a helpful and informative way. I'm a part of a knowledge base that contains a vast amount of information on various topics, and I can provide answers to your questions, help you with tasks, and even engage in conversations. I'm constantly learning and improving, so I can become more accurate and helpful over time. I'm happy to chat with you and provide assistance as needed!\n"
          ]
        }
      ],
      "source": [
        "response_translation = translation_chain({\n",
        "    \"user_query\": \"who are you?\"\n",
        "})\n",
        "print(\"your clone:\", response_translation[\"text\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HDJHjuf0Z20o"
      },
      "source": [
        "# **2️⃣ Data Loading, Chunking & Splitting**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "collapsed": true,
        "id": "rIcAWLNJaNmt",
        "outputId": "32f2038a-a58e-49f7-e65b-4ecf15d9e0b3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (2.0.2)\n",
            "Collecting PyPDF2\n",
            "  Downloading pypdf2-3.0.1-py3-none-any.whl.metadata (6.8 kB)\n",
            "Requirement already satisfied: langchain in /usr/local/lib/python3.11/dist-packages (0.3.25)\n",
            "Collecting chromadb\n",
            "  Downloading chromadb-1.0.9-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.9 kB)\n",
            "Collecting langchain-huggingface\n",
            "  Downloading langchain_huggingface-0.2.0-py3-none-any.whl.metadata (941 bytes)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.1)\n",
            "Collecting streamlit\n",
            "  Downloading streamlit-1.45.1-py3-none-any.whl.metadata (8.9 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (2.32.3)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: groq in /usr/local/lib/python3.11/dist-packages (0.25.0)\n",
            "Collecting langchain_community\n",
            "  Downloading langchain_community-0.3.24-py3-none-any.whl.metadata (2.5 kB)\n",
            "Requirement already satisfied: langchain-core<1.0.0,>=0.3.58 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.59)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.8 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.8)\n",
            "Requirement already satisfied: langsmith<0.4,>=0.1.17 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.42)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.11.4)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.0.40)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain) (6.0.2)\n",
            "Requirement already satisfied: build>=1.0.3 in /usr/local/lib/python3.11/dist-packages (from chromadb) (1.2.2.post1)\n",
            "Collecting fastapi==0.115.9 (from chromadb)\n",
            "  Downloading fastapi-0.115.9-py3-none-any.whl.metadata (27 kB)\n",
            "Collecting uvicorn>=0.18.3 (from uvicorn[standard]>=0.18.3->chromadb)\n",
            "  Downloading uvicorn-0.34.2-py3-none-any.whl.metadata (6.5 kB)\n",
            "Collecting posthog>=2.4.0 (from chromadb)\n",
            "  Downloading posthog-4.0.1-py2.py3-none-any.whl.metadata (3.0 kB)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (4.13.2)\n",
            "Collecting onnxruntime>=1.14.1 (from chromadb)\n",
            "  Downloading onnxruntime-1.22.0-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (4.5 kB)\n",
            "Collecting opentelemetry-api>=1.2.0 (from chromadb)\n",
            "  Downloading opentelemetry_api-1.33.1-py3-none-any.whl.metadata (1.6 kB)\n",
            "Collecting opentelemetry-exporter-otlp-proto-grpc>=1.2.0 (from chromadb)\n",
            "  Downloading opentelemetry_exporter_otlp_proto_grpc-1.33.1-py3-none-any.whl.metadata (2.5 kB)\n",
            "Collecting opentelemetry-instrumentation-fastapi>=0.41b0 (from chromadb)\n",
            "  Downloading opentelemetry_instrumentation_fastapi-0.54b1-py3-none-any.whl.metadata (2.2 kB)\n",
            "Collecting opentelemetry-sdk>=1.2.0 (from chromadb)\n",
            "  Downloading opentelemetry_sdk-1.33.1-py3-none-any.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: tokenizers>=0.13.2 in /usr/local/lib/python3.11/dist-packages (from chromadb) (0.21.1)\n",
            "Collecting pypika>=0.48.9 (from chromadb)\n",
            "  Downloading PyPika-0.48.9.tar.gz (67 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.3/67.3 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: tqdm>=4.65.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (4.67.1)\n",
            "Collecting overrides>=7.3.1 (from chromadb)\n",
            "  Downloading overrides-7.7.0-py3-none-any.whl.metadata (5.8 kB)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.11/dist-packages (from chromadb) (6.5.2)\n",
            "Requirement already satisfied: grpcio>=1.58.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (1.71.0)\n",
            "Collecting bcrypt>=4.0.1 (from chromadb)\n",
            "  Downloading bcrypt-4.3.0-cp39-abi3-manylinux_2_34_x86_64.whl.metadata (10 kB)\n",
            "Requirement already satisfied: typer>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (0.15.3)\n",
            "Collecting kubernetes>=28.1.0 (from chromadb)\n",
            "  Downloading kubernetes-32.0.1-py2.py3-none-any.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: tenacity>=8.2.3 in /usr/local/lib/python3.11/dist-packages (from chromadb) (9.1.2)\n",
            "Collecting mmh3>=4.0.1 (from chromadb)\n",
            "  Downloading mmh3-5.1.0-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (16 kB)\n",
            "Requirement already satisfied: orjson>=3.9.12 in /usr/local/lib/python3.11/dist-packages (from chromadb) (3.10.18)\n",
            "Requirement already satisfied: httpx>=0.27.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (0.28.1)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (13.9.4)\n",
            "Requirement already satisfied: jsonschema>=4.19.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (4.23.0)\n",
            "Collecting starlette<0.46.0,>=0.40.0 (from fastapi==0.115.9->chromadb)\n",
            "  Downloading starlette-0.45.3-py3-none-any.whl.metadata (6.3 kB)\n",
            "Requirement already satisfied: transformers>=4.39.0 in /usr/local/lib/python3.11/dist-packages (from langchain-huggingface) (4.51.3)\n",
            "Requirement already satisfied: sentence-transformers>=2.6.0 in /usr/local/lib/python3.11/dist-packages (from langchain-huggingface) (4.1.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.30.2 in /usr/local/lib/python3.11/dist-packages (from langchain-huggingface) (0.31.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.15.3)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.5.0)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: altair<6,>=4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.5.0)\n",
            "Requirement already satisfied: blinker<2,>=1.5.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (1.9.0)\n",
            "Requirement already satisfied: cachetools<6,>=4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.5.2)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (8.2.0)\n",
            "Requirement already satisfied: packaging<25,>=20 in /usr/local/lib/python3.11/dist-packages (from streamlit) (24.2)\n",
            "Requirement already satisfied: pillow<12,>=7.1.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (11.2.1)\n",
            "Requirement already satisfied: protobuf<7,>=3.20 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.29.4)\n",
            "Requirement already satisfied: pyarrow>=7.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (18.1.0)\n",
            "Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.11/dist-packages (from streamlit) (0.10.2)\n",
            "Collecting watchdog<7,>=2.1.5 (from streamlit)\n",
            "  Downloading watchdog-6.0.0-py3-none-manylinux2014_x86_64.whl.metadata (44 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.3/44.3 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in /usr/local/lib/python3.11/dist-packages (from streamlit) (3.1.44)\n",
            "Collecting pydeck<1,>=0.8.0b4 (from streamlit)\n",
            "  Downloading pydeck-0.9.1-py2.py3-none-any.whl.metadata (4.1 kB)\n",
            "Requirement already satisfied: tornado<7,>=6.0.3 in /usr/local/lib/python3.11/dist-packages (from streamlit) (6.4.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests) (2025.4.26)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from groq) (4.9.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from groq) (1.9.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from groq) (1.3.1)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (3.11.15)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain_community)\n",
            "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
            "Collecting pydantic-settings<3.0.0,>=2.4.0 (from langchain_community)\n",
            "  Downloading pydantic_settings-2.9.1-py3-none-any.whl.metadata (3.8 kB)\n",
            "Collecting httpx-sse<1.0.0,>=0.4.0 (from langchain_community)\n",
            "  Downloading httpx_sse-0.4.0-py3-none-any.whl.metadata (9.0 kB)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.6.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (6.4.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.20.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit) (3.1.6)\n",
            "Requirement already satisfied: narwhals>=1.14.2 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit) (1.39.0)\n",
            "Requirement already satisfied: pyproject_hooks in /usr/local/lib/python3.11/dist-packages (from build>=1.0.3->chromadb) (1.2.0)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
            "  Downloading marshmallow-3.26.1-py3-none-any.whl.metadata (7.3 kB)\n",
            "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.12)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.27.0->chromadb) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.27.0->chromadb) (0.16.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.30.2->langchain-huggingface) (3.18.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.30.2->langchain-huggingface) (2025.3.2)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=4.19.0->chromadb) (2025.4.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=4.19.0->chromadb) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=4.19.0->chromadb) (0.24.0)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (1.17.0)\n",
            "Requirement already satisfied: google-auth>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (2.38.0)\n",
            "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (1.8.0)\n",
            "Requirement already satisfied: requests-oauthlib in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (2.0.0)\n",
            "Requirement already satisfied: oauthlib>=3.2.2 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (3.2.2)\n",
            "Collecting durationpy>=0.7 (from kubernetes>=28.1.0->chromadb)\n",
            "  Downloading durationpy-0.9-py3-none-any.whl.metadata (338 bytes)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.58->langchain) (1.33)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (0.23.0)\n",
            "Collecting coloredlogs (from onnxruntime>=1.14.1->chromadb)\n",
            "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.11/dist-packages (from onnxruntime>=1.14.1->chromadb) (25.2.10)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from onnxruntime>=1.14.1->chromadb) (1.13.1)\n",
            "Collecting deprecated>=1.2.6 (from opentelemetry-api>=1.2.0->chromadb)\n",
            "  Downloading Deprecated-1.2.18-py2.py3-none-any.whl.metadata (5.7 kB)\n",
            "Collecting importlib-metadata<8.7.0,>=6.0 (from opentelemetry-api>=1.2.0->chromadb)\n",
            "  Downloading importlib_metadata-8.6.1-py3-none-any.whl.metadata (4.7 kB)\n",
            "Requirement already satisfied: googleapis-common-protos~=1.52 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.70.0)\n",
            "Collecting opentelemetry-exporter-otlp-proto-common==1.33.1 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb)\n",
            "  Downloading opentelemetry_exporter_otlp_proto_common-1.33.1-py3-none-any.whl.metadata (1.9 kB)\n",
            "Collecting opentelemetry-proto==1.33.1 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb)\n",
            "  Downloading opentelemetry_proto-1.33.1-py3-none-any.whl.metadata (2.4 kB)\n",
            "Collecting opentelemetry-instrumentation-asgi==0.54b1 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
            "  Downloading opentelemetry_instrumentation_asgi-0.54b1-py3-none-any.whl.metadata (2.1 kB)\n",
            "Collecting opentelemetry-instrumentation==0.54b1 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
            "  Downloading opentelemetry_instrumentation-0.54b1-py3-none-any.whl.metadata (6.8 kB)\n",
            "Collecting opentelemetry-semantic-conventions==0.54b1 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
            "  Downloading opentelemetry_semantic_conventions-0.54b1-py3-none-any.whl.metadata (2.5 kB)\n",
            "Collecting opentelemetry-util-http==0.54b1 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
            "  Downloading opentelemetry_util_http-0.54b1-py3-none-any.whl.metadata (2.6 kB)\n",
            "Requirement already satisfied: wrapt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-instrumentation==0.54b1->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (1.17.2)\n",
            "Collecting asgiref~=3.0 (from opentelemetry-instrumentation-asgi==0.54b1->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
            "  Downloading asgiref-3.8.1-py3-none-any.whl.metadata (9.3 kB)\n",
            "Collecting backoff>=1.10.0 (from posthog>=2.4.0->chromadb)\n",
            "  Downloading backoff-2.2.1-py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.0)\n",
            "Collecting python-dotenv>=0.21.0 (from pydantic-settings<3.0.0,>=2.4.0->langchain_community)\n",
            "  Downloading python_dotenv-1.1.0-py3-none-any.whl.metadata (24 kB)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->chromadb) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->chromadb) (2.19.1)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers>=2.6.0->langchain-huggingface) (2.6.0+cu124)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.2.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.39.0->langchain-huggingface) (2024.11.6)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.39.0->langchain-huggingface) (0.5.3)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer>=0.9.0->chromadb) (1.5.4)\n",
            "Collecting httptools>=0.6.3 (from uvicorn[standard]>=0.18.3->chromadb)\n",
            "  Downloading httptools-0.6.4-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.6 kB)\n",
            "Collecting uvloop!=0.15.0,!=0.15.1,>=0.14.0 (from uvicorn[standard]>=0.18.3->chromadb)\n",
            "  Downloading uvloop-0.21.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
            "Collecting watchfiles>=0.13 (from uvicorn[standard]>=0.18.3->chromadb)\n",
            "  Downloading watchfiles-1.0.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
            "Requirement already satisfied: websockets>=10.4 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (15.0.1)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit) (5.0.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (4.9.1)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.11/dist-packages (from importlib-metadata<8.7.0,>=6.0->opentelemetry-api>=1.2.0->chromadb) (3.21.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->altair<6,>=4.0->streamlit) (3.0.2)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.58->langchain) (3.0.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->chromadb) (0.1.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (3.4.2)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (3.2.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->onnxruntime>=1.14.1->chromadb) (1.3.0)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
            "  Downloading mypy_extensions-1.1.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime>=1.14.1->chromadb)\n",
            "  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.6.1)\n",
            "Downloading pypdf2-3.0.1-py3-none-any.whl (232 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m232.6/232.6 kB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading chromadb-1.0.9-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.9/18.9 MB\u001b[0m \u001b[31m86.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fastapi-0.115.9-py3-none-any.whl (94 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m94.9/94.9 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_huggingface-0.2.0-py3-none-any.whl (27 kB)\n",
            "Downloading streamlit-1.45.1-py3-none-any.whl (9.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.9/9.9 MB\u001b[0m \u001b[31m107.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_community-0.3.24-py3-none-any.whl (2.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m78.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading bcrypt-4.3.0-cp39-abi3-manylinux_2_34_x86_64.whl (284 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m284.2/284.2 kB\u001b[0m \u001b[31m20.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
            "Downloading httpx_sse-0.4.0-py3-none-any.whl (7.8 kB)\n",
            "Downloading kubernetes-32.0.1-py2.py3-none-any.whl (2.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m68.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mmh3-5.1.0-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (101 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.6/101.6 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading onnxruntime-1.22.0-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (16.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.4/16.4 MB\u001b[0m \u001b[31m93.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opentelemetry_api-1.33.1-py3-none-any.whl (65 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.8/65.8 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opentelemetry_exporter_otlp_proto_grpc-1.33.1-py3-none-any.whl (18 kB)\n",
            "Downloading opentelemetry_exporter_otlp_proto_common-1.33.1-py3-none-any.whl (18 kB)\n",
            "Downloading opentelemetry_proto-1.33.1-py3-none-any.whl (55 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.9/55.9 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opentelemetry_instrumentation_fastapi-0.54b1-py3-none-any.whl (12 kB)\n",
            "Downloading opentelemetry_instrumentation-0.54b1-py3-none-any.whl (31 kB)\n",
            "Downloading opentelemetry_instrumentation_asgi-0.54b1-py3-none-any.whl (16 kB)\n",
            "Downloading opentelemetry_semantic_conventions-0.54b1-py3-none-any.whl (194 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.9/194.9 kB\u001b[0m \u001b[31m16.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opentelemetry_util_http-0.54b1-py3-none-any.whl (7.3 kB)\n",
            "Downloading opentelemetry_sdk-1.33.1-py3-none-any.whl (118 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m119.0/119.0 kB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading overrides-7.7.0-py3-none-any.whl (17 kB)\n",
            "Downloading posthog-4.0.1-py2.py3-none-any.whl (92 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.0/92.0 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydantic_settings-2.9.1-py3-none-any.whl (44 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.4/44.4 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydeck-0.9.1-py2.py3-none-any.whl (6.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m102.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading uvicorn-0.34.2-py3-none-any.whl (62 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.5/62.5 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading watchdog-6.0.0-py3-none-manylinux2014_x86_64.whl (79 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.1/79.1 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading backoff-2.2.1-py3-none-any.whl (15 kB)\n",
            "Downloading Deprecated-1.2.18-py2.py3-none-any.whl (10.0 kB)\n",
            "Downloading durationpy-0.9-py3-none-any.whl (3.5 kB)\n",
            "Downloading httptools-0.6.4-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (459 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m459.8/459.8 kB\u001b[0m \u001b[31m34.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading importlib_metadata-8.6.1-py3-none-any.whl (26 kB)\n",
            "Downloading marshmallow-3.26.1-py3-none-any.whl (50 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_dotenv-1.1.0-py3-none-any.whl (20 kB)\n",
            "Downloading starlette-0.45.3-py3-none-any.whl (71 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.5/71.5 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m53.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m34.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m46.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m12.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m91.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Downloading uvloop-0.21.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.0/4.0 MB\u001b[0m \u001b[31m95.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading watchfiles-1.0.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (454 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m454.8/454.8 kB\u001b[0m \u001b[31m32.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading asgiref-3.8.1-py3-none-any.whl (23 kB)\n",
            "Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mypy_extensions-1.1.0-py3-none-any.whl (5.0 kB)\n",
            "Building wheels for collected packages: pypika\n",
            "  Building wheel for pypika (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pypika: filename=pypika-0.48.9-py2.py3-none-any.whl size=53801 sha256=5fe7509bf678628eea764123417df7653b4bf0ccd0af87edd5ef243c5e714040\n",
            "  Stored in directory: /root/.cache/pip/wheels/a3/01/bd/4c40ceb9d5354160cb186dcc153360f4ab7eb23e2b24daf96d\n",
            "Successfully built pypika\n",
            "Installing collected packages: pypika, durationpy, watchdog, uvloop, uvicorn, python-dotenv, PyPDF2, overrides, opentelemetry-util-http, opentelemetry-proto, nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, mypy-extensions, mmh3, marshmallow, importlib-metadata, humanfriendly, httpx-sse, httptools, deprecated, bcrypt, backoff, asgiref, watchfiles, typing-inspect, starlette, pydeck, posthog, opentelemetry-exporter-otlp-proto-common, opentelemetry-api, nvidia-cusparse-cu12, nvidia-cudnn-cu12, coloredlogs, pydantic-settings, opentelemetry-semantic-conventions, onnxruntime, nvidia-cusolver-cu12, kubernetes, fastapi, dataclasses-json, opentelemetry-sdk, opentelemetry-instrumentation, streamlit, opentelemetry-instrumentation-asgi, opentelemetry-exporter-otlp-proto-grpc, opentelemetry-instrumentation-fastapi, langchain-huggingface, langchain_community, chromadb\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: importlib-metadata\n",
            "    Found existing installation: importlib_metadata 8.7.0\n",
            "    Uninstalling importlib_metadata-8.7.0:\n",
            "      Successfully uninstalled importlib_metadata-8.7.0\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed PyPDF2-3.0.1 asgiref-3.8.1 backoff-2.2.1 bcrypt-4.3.0 chromadb-1.0.9 coloredlogs-15.0.1 dataclasses-json-0.6.7 deprecated-1.2.18 durationpy-0.9 fastapi-0.115.9 httptools-0.6.4 httpx-sse-0.4.0 humanfriendly-10.0 importlib-metadata-8.6.1 kubernetes-32.0.1 langchain-huggingface-0.2.0 langchain_community-0.3.24 marshmallow-3.26.1 mmh3-5.1.0 mypy-extensions-1.1.0 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 onnxruntime-1.22.0 opentelemetry-api-1.33.1 opentelemetry-exporter-otlp-proto-common-1.33.1 opentelemetry-exporter-otlp-proto-grpc-1.33.1 opentelemetry-instrumentation-0.54b1 opentelemetry-instrumentation-asgi-0.54b1 opentelemetry-instrumentation-fastapi-0.54b1 opentelemetry-proto-1.33.1 opentelemetry-sdk-1.33.1 opentelemetry-semantic-conventions-0.54b1 opentelemetry-util-http-0.54b1 overrides-7.7.0 posthog-4.0.1 pydantic-settings-2.9.1 pydeck-0.9.1 pypika-0.48.9 python-dotenv-1.1.0 starlette-0.45.3 streamlit-1.45.1 typing-inspect-0.9.0 uvicorn-0.34.2 uvloop-0.21.0 watchdog-6.0.0 watchfiles-1.0.5\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "importlib_metadata"
                ]
              },
              "id": "9db466b13c8a4f2fb03f064cdc59b377"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "!pip install numpy PyPDF2 langchain chromadb langchain-huggingface scikit-learn streamlit requests pandas groq langchain_community"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qPfedkxwCSrV"
      },
      "source": [
        "Extracting text from PDFs, splitting it into manageable chunks, and preparing it for vector storage."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip uninstall -y opentelemetry-exporter-otlp-proto-grpc opentelemetry-api opentelemetry-sdk\n",
        "!pip install opentelemetry-api==1.18.0 opentelemetry-sdk==1.18.0 opentelemetry-exporter-otlp-proto-grpc==1.18.0\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "KZ42ikgYUtgK",
        "outputId": "7a610390-47b1-47f9-e925-48f5ef1ba146"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: opentelemetry-exporter-otlp-proto-grpc 1.33.1\n",
            "Uninstalling opentelemetry-exporter-otlp-proto-grpc-1.33.1:\n",
            "  Successfully uninstalled opentelemetry-exporter-otlp-proto-grpc-1.33.1\n",
            "Found existing installation: opentelemetry-api 1.33.1\n",
            "Uninstalling opentelemetry-api-1.33.1:\n",
            "  Successfully uninstalled opentelemetry-api-1.33.1\n",
            "Found existing installation: opentelemetry-sdk 1.33.1\n",
            "Uninstalling opentelemetry-sdk-1.33.1:\n",
            "  Successfully uninstalled opentelemetry-sdk-1.33.1\n",
            "Collecting opentelemetry-api==1.18.0\n",
            "  Downloading opentelemetry_api-1.18.0-py3-none-any.whl.metadata (1.4 kB)\n",
            "Collecting opentelemetry-sdk==1.18.0\n",
            "  Downloading opentelemetry_sdk-1.18.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting opentelemetry-exporter-otlp-proto-grpc==1.18.0\n",
            "  Downloading opentelemetry_exporter_otlp_proto_grpc-1.18.0-py3-none-any.whl.metadata (2.4 kB)\n",
            "Requirement already satisfied: deprecated>=1.2.6 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-api==1.18.0) (1.2.18)\n",
            "Collecting importlib-metadata~=6.0.0 (from opentelemetry-api==1.18.0)\n",
            "  Downloading importlib_metadata-6.0.1-py3-none-any.whl.metadata (5.0 kB)\n",
            "Requirement already satisfied: setuptools>=16.0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-api==1.18.0) (75.2.0)\n",
            "Collecting opentelemetry-semantic-conventions==0.39b0 (from opentelemetry-sdk==1.18.0)\n",
            "  Downloading opentelemetry_semantic_conventions-0.39b0-py3-none-any.whl.metadata (2.3 kB)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-sdk==1.18.0) (4.13.2)\n",
            "Requirement already satisfied: backoff<3.0.0,>=1.10.0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-exporter-otlp-proto-grpc==1.18.0) (2.2.1)\n",
            "Requirement already satisfied: googleapis-common-protos~=1.52 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-exporter-otlp-proto-grpc==1.18.0) (1.70.0)\n",
            "Requirement already satisfied: grpcio<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-exporter-otlp-proto-grpc==1.18.0) (1.71.0)\n",
            "Collecting opentelemetry-exporter-otlp-proto-common==1.18.0 (from opentelemetry-exporter-otlp-proto-grpc==1.18.0)\n",
            "  Downloading opentelemetry_exporter_otlp_proto_common-1.18.0-py3-none-any.whl.metadata (1.7 kB)\n",
            "Collecting opentelemetry-proto==1.18.0 (from opentelemetry-exporter-otlp-proto-grpc==1.18.0)\n",
            "  Downloading opentelemetry_proto-1.18.0-py3-none-any.whl.metadata (2.3 kB)\n",
            "Collecting protobuf<5.0,>=3.19 (from opentelemetry-proto==1.18.0->opentelemetry-exporter-otlp-proto-grpc==1.18.0)\n",
            "  Downloading protobuf-4.25.7-cp37-abi3-manylinux2014_x86_64.whl.metadata (541 bytes)\n",
            "Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.11/dist-packages (from deprecated>=1.2.6->opentelemetry-api==1.18.0) (1.17.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.11/dist-packages (from importlib-metadata~=6.0.0->opentelemetry-api==1.18.0) (3.21.0)\n",
            "Downloading opentelemetry_api-1.18.0-py3-none-any.whl (57 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.3/57.3 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opentelemetry_sdk-1.18.0-py3-none-any.whl (101 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.6/101.6 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opentelemetry_exporter_otlp_proto_grpc-1.18.0-py3-none-any.whl (18 kB)\n",
            "Downloading opentelemetry_exporter_otlp_proto_common-1.18.0-py3-none-any.whl (17 kB)\n",
            "Downloading opentelemetry_proto-1.18.0-py3-none-any.whl (52 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.6/52.6 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opentelemetry_semantic_conventions-0.39b0-py3-none-any.whl (26 kB)\n",
            "Downloading importlib_metadata-6.0.1-py3-none-any.whl (21 kB)\n",
            "Downloading protobuf-4.25.7-cp37-abi3-manylinux2014_x86_64.whl (294 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m294.6/294.6 kB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: protobuf, opentelemetry-semantic-conventions, importlib-metadata, opentelemetry-proto, opentelemetry-api, opentelemetry-sdk, opentelemetry-exporter-otlp-proto-common, opentelemetry-exporter-otlp-proto-grpc\n",
            "  Attempting uninstall: protobuf\n",
            "    Found existing installation: protobuf 5.29.4\n",
            "    Uninstalling protobuf-5.29.4:\n",
            "      Successfully uninstalled protobuf-5.29.4\n",
            "  Attempting uninstall: opentelemetry-semantic-conventions\n",
            "    Found existing installation: opentelemetry-semantic-conventions 0.54b1\n",
            "    Uninstalling opentelemetry-semantic-conventions-0.54b1:\n",
            "      Successfully uninstalled opentelemetry-semantic-conventions-0.54b1\n",
            "  Attempting uninstall: importlib-metadata\n",
            "    Found existing installation: importlib_metadata 8.6.1\n",
            "    Uninstalling importlib_metadata-8.6.1:\n",
            "      Successfully uninstalled importlib_metadata-8.6.1\n",
            "  Attempting uninstall: opentelemetry-proto\n",
            "    Found existing installation: opentelemetry-proto 1.33.1\n",
            "    Uninstalling opentelemetry-proto-1.33.1:\n",
            "      Successfully uninstalled opentelemetry-proto-1.33.1\n",
            "  Attempting uninstall: opentelemetry-exporter-otlp-proto-common\n",
            "    Found existing installation: opentelemetry-exporter-otlp-proto-common 1.33.1\n",
            "    Uninstalling opentelemetry-exporter-otlp-proto-common-1.33.1:\n",
            "      Successfully uninstalled opentelemetry-exporter-otlp-proto-common-1.33.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "opentelemetry-instrumentation-asgi 0.54b1 requires opentelemetry-semantic-conventions==0.54b1, but you have opentelemetry-semantic-conventions 0.39b0 which is incompatible.\n",
            "opentelemetry-instrumentation-fastapi 0.54b1 requires opentelemetry-semantic-conventions==0.54b1, but you have opentelemetry-semantic-conventions 0.39b0 which is incompatible.\n",
            "opentelemetry-instrumentation 0.54b1 requires opentelemetry-semantic-conventions==0.54b1, but you have opentelemetry-semantic-conventions 0.39b0 which is incompatible.\n",
            "ydf 0.11.0 requires protobuf<6.0.0,>=5.29.1, but you have protobuf 4.25.7 which is incompatible.\n",
            "grpcio-status 1.71.0 requires protobuf<6.0dev,>=5.26.1, but you have protobuf 4.25.7 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed importlib-metadata-6.0.1 opentelemetry-api-1.18.0 opentelemetry-exporter-otlp-proto-common-1.18.0 opentelemetry-exporter-otlp-proto-grpc-1.18.0 opentelemetry-proto-1.18.0 opentelemetry-sdk-1.18.0 opentelemetry-semantic-conventions-0.39b0 protobuf-4.25.7\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "importlib_metadata"
                ]
              },
              "id": "0bae1a21724f439ea4719e4f6f3a18ba"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZTsqBcbO_4N4",
        "outputId": "ebbf2eb0-cc31-4b71-c857-65e030e811be"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Extracted text from PDF with 3 pages.\n"
          ]
        }
      ],
      "source": [
        "# Step 1: Upload and Load PDF\n",
        "from PyPDF2 import PdfReader\n",
        "\n",
        "def load_pdf(file):\n",
        "    \"\"\"Load and extract text from a PDF file.\"\"\"\n",
        "    try:\n",
        "        reader = PdfReader(file)\n",
        "        text = \"\".join([page.extract_text() or \"\" for page in reader.pages])\n",
        "        print(f\"✅ Extracted text from PDF with {len(reader.pages)} pages.\")\n",
        "        return text\n",
        "    except Exception as e:\n",
        "        print(f\"⚠️ Error reading PDF: {str(e)}\")\n",
        "        return \"\"\n",
        "\n",
        "# Upload your PDF file (Replace with the actual file path)\n",
        "pdf_file_path = \"/content/Divya_Profile_Complete.pdf\"\n",
        "pdf_text = load_pdf(pdf_file_path)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qCjqvzR2BDX6"
      },
      "source": [
        "**2.1 Chunking the Extracted Text**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kSoMdMbtBFTB",
        "outputId": "436712b9-e932-4113-8bdf-1c0e79c9a6d8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Text chunked into 7 chunks, with chunk size of 500.\n"
          ]
        }
      ],
      "source": [
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "\n",
        "def chunk_text(text):\n",
        "    \"\"\"Split the extracted text into smaller chunks dynamically based on text length.\"\"\"\n",
        "    chunk_size = 500\n",
        "    splitter = RecursiveCharacterTextSplitter(chunk_size=chunk_size, chunk_overlap=150)\n",
        "    chunks = splitter.split_text(text)\n",
        "    print(f\"✅ Text chunked into {len(chunks)} chunks, with chunk size of {chunk_size}.\")\n",
        "    return chunks\n",
        "\n",
        "if pdf_text.strip():\n",
        "    chunks = chunk_text(pdf_text)\n",
        "else:\n",
        "    print(\"⚠️ No text extracted from PDF. Please check your file.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        },
        "id": "YvGSu0KgbCa2",
        "outputId": "99e338c4-cc09-435b-decb-406edb381f9d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'User Profile: Divya\\nComplete Profile Overview\\nName: Divya\\nRole: Engineering Student aspiring for a career in Data Science and Machine Learning.\\nCareer Goals:\\n- Secure a 30 LPA package in a good company.\\n- Master Data Science, ML, DL, NLP, Neural Networks, LLMs, GenAI, and Cloud Technologies like Azure.\\n- Become a job-ready Python backend developer and full stack web developer.\\nCurrent Projects:\\n- Mortgage-Based Security Analysis and Prediction\\n- Big Mart Analysis and Prediction'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "chunks[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "id": "lTUTkONcbE9q",
        "outputId": "e5358eaa-d40a-4352-a97b-ad2b4368d6c1"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Current Projects:\\n- Mortgage-Based Security Analysis and Prediction\\n- Big Mart Analysis and Prediction\\n- Customer Churn Prediction\\n- Startup Acquisition Status Modeling\\n- AutoDoc: AI-Based Automated Document Summarization and Tagging System\\nSkills & Interests:\\n- Machine Learning: Classification, Regression, Model Pipelines, Deployment (Flask)\\n- Strong focus on learning DSA, ML algorithms, Model Optimization (Hyperparameter Tuning)'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "chunks[1]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c3ps24iXCXeW"
      },
      "source": [
        "# **3️⃣ Embeddings & Vector Database Creation**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YGlBBS5tCbwm"
      },
      "source": [
        "Generating embeddings using Hugging Face models and storing them in ChromaDB for efficient retrieval."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip uninstall -y opentelemetry-exporter-otlp-proto-grpc opentelemetry-api opentelemetry-sdk\n",
        "!pip install opentelemetry-api==1.18.0 opentelemetry-sdk==1.18.0 opentelemetry-exporter-otlp-proto-grpc==1.18.0\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "92aU54C5T-TJ",
        "outputId": "dcce3c18-9771-4029-e532-1c0c1cc638b9"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: opentelemetry-exporter-otlp-proto-grpc 1.18.0\n",
            "Uninstalling opentelemetry-exporter-otlp-proto-grpc-1.18.0:\n",
            "  Successfully uninstalled opentelemetry-exporter-otlp-proto-grpc-1.18.0\n",
            "Found existing installation: opentelemetry-api 1.18.0\n",
            "Uninstalling opentelemetry-api-1.18.0:\n",
            "  Successfully uninstalled opentelemetry-api-1.18.0\n",
            "Found existing installation: opentelemetry-sdk 1.18.0\n",
            "Uninstalling opentelemetry-sdk-1.18.0:\n",
            "  Successfully uninstalled opentelemetry-sdk-1.18.0\n",
            "Collecting opentelemetry-api==1.18.0\n",
            "  Using cached opentelemetry_api-1.18.0-py3-none-any.whl.metadata (1.4 kB)\n",
            "Collecting opentelemetry-sdk==1.18.0\n",
            "  Using cached opentelemetry_sdk-1.18.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting opentelemetry-exporter-otlp-proto-grpc==1.18.0\n",
            "  Using cached opentelemetry_exporter_otlp_proto_grpc-1.18.0-py3-none-any.whl.metadata (2.4 kB)\n",
            "Requirement already satisfied: deprecated>=1.2.6 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-api==1.18.0) (1.2.18)\n",
            "Requirement already satisfied: importlib-metadata~=6.0.0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-api==1.18.0) (6.0.1)\n",
            "Requirement already satisfied: setuptools>=16.0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-api==1.18.0) (75.2.0)\n",
            "Requirement already satisfied: opentelemetry-semantic-conventions==0.39b0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-sdk==1.18.0) (0.39b0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-sdk==1.18.0) (4.13.2)\n",
            "Requirement already satisfied: backoff<3.0.0,>=1.10.0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-exporter-otlp-proto-grpc==1.18.0) (2.2.1)\n",
            "Requirement already satisfied: googleapis-common-protos~=1.52 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-exporter-otlp-proto-grpc==1.18.0) (1.70.0)\n",
            "Requirement already satisfied: grpcio<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-exporter-otlp-proto-grpc==1.18.0) (1.71.0)\n",
            "Requirement already satisfied: opentelemetry-exporter-otlp-proto-common==1.18.0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-exporter-otlp-proto-grpc==1.18.0) (1.18.0)\n",
            "Requirement already satisfied: opentelemetry-proto==1.18.0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-exporter-otlp-proto-grpc==1.18.0) (1.18.0)\n",
            "Requirement already satisfied: protobuf<5.0,>=3.19 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-proto==1.18.0->opentelemetry-exporter-otlp-proto-grpc==1.18.0) (4.25.7)\n",
            "Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.11/dist-packages (from deprecated>=1.2.6->opentelemetry-api==1.18.0) (1.17.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.11/dist-packages (from importlib-metadata~=6.0.0->opentelemetry-api==1.18.0) (3.21.0)\n",
            "Using cached opentelemetry_api-1.18.0-py3-none-any.whl (57 kB)\n",
            "Using cached opentelemetry_sdk-1.18.0-py3-none-any.whl (101 kB)\n",
            "Using cached opentelemetry_exporter_otlp_proto_grpc-1.18.0-py3-none-any.whl (18 kB)\n",
            "Installing collected packages: opentelemetry-api, opentelemetry-sdk, opentelemetry-exporter-otlp-proto-grpc\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "opentelemetry-instrumentation-asgi 0.54b1 requires opentelemetry-semantic-conventions==0.54b1, but you have opentelemetry-semantic-conventions 0.39b0 which is incompatible.\n",
            "opentelemetry-instrumentation-fastapi 0.54b1 requires opentelemetry-semantic-conventions==0.54b1, but you have opentelemetry-semantic-conventions 0.39b0 which is incompatible.\n",
            "opentelemetry-instrumentation 0.54b1 requires opentelemetry-semantic-conventions==0.54b1, but you have opentelemetry-semantic-conventions 0.39b0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed opentelemetry-api-1.18.0 opentelemetry-exporter-otlp-proto-grpc-1.18.0 opentelemetry-sdk-1.18.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 550,
          "referenced_widgets": [
            "d3a2a70a0d144df4a58aff567a18a5d6",
            "5d36bc91258b4e848c5870d40c5bb85b",
            "2e7bd5ff30514562b770cbe76f269c93",
            "fb1bc9d705da4d91bd3c412c96fa4e95",
            "c40964cdd59e42a1afa9e138f7faf878",
            "175f7ea90fd0484a863761f6508d76cf",
            "f5853ce3d75b4646895fa999de7fdb6a",
            "f1dea63b2ffb44d88c765f773b127634",
            "79ee24ed406e4fef89505d966579f254",
            "50acb6f821e343dd8ce0470617b596d7",
            "3ef7b965fa51409e87c25219d92ad727",
            "64c6deb742f645959403574c93a2a6c6",
            "d3dd2366af2a4c1d8ab3c5e173119b93",
            "3ad9708c0ccf4abba5c84f772303619a",
            "9990dcab105b47f7b893dfd5fdb21b53",
            "139b0b9389c746cc808922ef30e73284",
            "5c52a9198d924c42bf6d27ca0c1ac382",
            "9173e7101f874d3c9f92742369b9a289",
            "20c0242d75f84fd2b21d9f1955fd8267",
            "dafe3ff7d9e4411aba90b512af172abb",
            "a34b3571276242c89e83f7e252525d45",
            "1eac8b400c0443079efa6569cc01aa81",
            "1ac9859aecd94a6c83e8be48e59e8d4f",
            "990bb927a0d14a8eba27cff6c4285233",
            "f5bd9682d7c447ad9e1c9fa1b1f8e434",
            "d4bda4952c9a4059861a28b168bcba07",
            "44bd995520d74efa9bee75309c6c4d0d",
            "7a24b5850e054d7f8893c25369a85985",
            "e5808515dda84e1db04d964cc69c844a",
            "9ff0c00f36714b21a13fcde0000a9861",
            "573473762cd64dd6ad38c49896e600c1",
            "6a1cc28e3263456a8d5e76f73d3bfe3b",
            "45dde094a58c43898d0d669211ddf7d1",
            "2e2fc99a413346f7a1a54ca30ace076f",
            "034d41ed95cf485e8e2759eaf27aab3d",
            "db983defb4bd41399d3eea38d44ecb7e",
            "5920c6f9d1e040298bd747489c342a37",
            "d63c654ece8d43348d959dc0fbaef8d2",
            "c8cede9ea0f94bfbbd14006677848958",
            "46203df1220a418eb8a60da786fd0594",
            "d613af8cc0384c299ea0b8d2470cedb1",
            "cb1300cdd8474e5c90734d8cfe04e20b",
            "3cfb439192074656b2c2cdf6a5a83196",
            "246f2373970246a0a56b40948b08530f",
            "a9dd71bfb1794111aa76d19df8a0edc8",
            "3d5b000c8fe04793a4ba5fc4fc8a5366",
            "aecb85fd296a41f08414f5ae64796f2f",
            "6d4bdfb1ee564fc7b9f70ef3ac3f935e",
            "18ee6a5870cf429c9ec4df55ef6e3c7f",
            "73d2ca89a5924fd8805c6df16804dcf0",
            "f162b391e9844a719606038d4a433bc9",
            "667d66fdc52f43dc80cbcd4545bb26d0",
            "751e438dce9343babd98f511f77dc316",
            "f03264c95c0e4ae78f2b605f58f00660",
            "d70e3d6765bb4bf0b182be877995328a",
            "725e65e253624c13ad6a8c39a3e9d68c",
            "09fcee3d010a4800ac89a47084c21801",
            "1a696bb2695648b5a5a2f51861ac6324",
            "ccf3b636f495451b822899b890042343",
            "5c28ba7a17ae45b99692d04b50471ae0",
            "77b73c791bee4178aa47d0646a8aca80",
            "a3731c95248540df9a2bd64cbe0b10b7",
            "f5681b220c19436484c3f47cfe082327",
            "2cfb99f4c78a441ebbe7ba4682ba677a",
            "eac6f38c6e7b46d9a8fa21bf4999330c",
            "52bb1c1dda1a433181468cd2ea5bdd15",
            "db6aef6e5eb64cd88c50065d1eefd992",
            "0013aec5d7bc40249967c9fb49796886",
            "1f705bc7e93c4e249715c6107d61589e",
            "5b0d7dcd406f41558510b16f634d262a",
            "b50d6dfd295f403fad5fb94c8dde0793",
            "74ff80ba829945a29cbbbb539cf06358",
            "92c9807214644c7c9ab9bb69ea3d9b74",
            "28f8e768be504154a90a0d2d05d27561",
            "0b1c677e9dcc420493fa9a4d15f0a5c2",
            "5c1fd96d9f2a4fc1bfab7f024fe083e5",
            "77360ad15d054c29ad498f00a1e4e763",
            "62c113a612004237aaec3c8e6b1f66df",
            "36a99a41b1f3430bbdcedfe87d6ec75a",
            "7c45e294ba614e8688856c150861e75a",
            "c892f360bc4340efbeeb746e1f3ed018",
            "2b31bbd91c7d473b995e87beaf8f7024",
            "64232849f7934591bad692c980744ed1",
            "fd7fd0aaf3be4f4392079c4bc63be3c6",
            "952cc63857bb4764986554c8e0a45748",
            "5e19b02531a54f688f7cd5ec4e913ade",
            "1ec1384ebe8f4651835b118d423e2a38",
            "bbe9283a2bd24d569c217dca1040162c",
            "1a561a2327a44e3c83dc77c32f75740c",
            "ab89004b05c2445ea6668ebd81d1dd5b",
            "02b9f92fdabb48dfbdf8addb31cfabf1",
            "dd17b0d6969e4393b11a185f1f6bee81",
            "6c869c6c26a64215ad74b3d1db011d01",
            "84ad83bcc643451ab858fb13e0623685",
            "f3ff2b8cdc7f44d0b00de3d9769e45b6",
            "b2f39fbb1b7f4c84ae53a7b5e9875e1f",
            "e825e22188d4404abf41a6184628a5c9",
            "402401baa61d4b64ad57c2dd9442ad3c",
            "cc62e7bd591e49ccb561fc1defcceecf",
            "8c005987480d490fae0edae639150754",
            "fe4d1e2bd8744f84869c89533c0f207d",
            "e51ec310d3b34d5c9ebc113d1bbc2ccf",
            "89512d3c12484ba5b4e653ae12536fb3",
            "73b50a92d3074e60a3a869518543bde0",
            "3cb7977642544b65a9b4ae92d2c97636",
            "708a0c6a54db41e881db21b7fd9b570f",
            "34201716a56640888fbfa866717c5a7a",
            "6e864e8472324f6ead29bb7269063298",
            "81ada964b1ab4d6390a97576f28e28eb",
            "bfdfcfb80c5643848d618e0c63c7d36f",
            "9cd3644f814b4a4c8bdc0d77dc3a8241",
            "66348d24995a4ba4aa30131fc9cbe4ca",
            "3f3ef8a56e784f46b79767979c2fce0e",
            "904d9490d2214e8385d15f92b7581ddf",
            "9f90dadc8331445aae7d84976a534334",
            "b311dcd5ec904259aff6594564fe69da",
            "372d22223f714656b6f07a148853b746",
            "2fee4088ccaf48b29ab84ef48beb3fcf",
            "9dbca64e82104523a31e96c509062f2f",
            "c8c99e8ec75240ef943c4334e906d868",
            "63c77d8a7b1547449525e6f156729a90"
          ]
        },
        "id": "lJk0fVuhFpKD",
        "outputId": "63056ce3-1264-43c9-af4a-f9abbe51d7b5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d3a2a70a0d144df4a58aff567a18a5d6"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "64c6deb742f645959403574c93a2a6c6"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "README.md:   0%|          | 0.00/10.5k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1ac9859aecd94a6c83e8be48e59e8d4f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2e2fc99a413346f7a1a54ca30ace076f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a9dd71bfb1794111aa76d19df8a0edc8"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
            "WARNING:huggingface_hub.file_download:Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "725e65e253624c13ad6a8c39a3e9d68c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "db6aef6e5eb64cd88c50065d1eefd992"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "62c113a612004237aaec3c8e6b1f66df"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1a561a2327a44e3c83dc77c32f75740c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8c005987480d490fae0edae639150754"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9cd3644f814b4a4c8bdc0d77dc3a8241"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ New embeddings stored in ChromaDB!\n"
          ]
        }
      ],
      "source": [
        "import chromadb\n",
        "from langchain_huggingface import HuggingFaceEmbeddings\n",
        "\n",
        "# Initialize embedding model\n",
        "embedding_model = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
        "\n",
        "# Initialize ChromaDB client and collection\n",
        "chroma_client = chromadb.PersistentClient(path=\"./chroma_db\")\n",
        "collection = chroma_client.get_or_create_collection(name=\"ai_knowledge_base\")\n",
        "\n",
        "# Retrieve existing stored documents\n",
        "existing_docs = set(collection.get().get(\"documents\", []))\n",
        "new_chunks = [chunk for chunk in chunks if chunk not in existing_docs]\n",
        "\n",
        "# Embed and store only new chunks\n",
        "if new_chunks:\n",
        "    embeddings = [embedding_model.embed_query(chunk) for chunk in new_chunks]\n",
        "    collection.add(\n",
        "        ids=[str(i) for i in range(len(existing_docs), len(existing_docs) + len(new_chunks))],\n",
        "        documents=new_chunks,\n",
        "        embeddings=embeddings\n",
        "    )\n",
        "    print(\"✅ New embeddings stored in ChromaDB!\")\n",
        "else:\n",
        "    print(f\"✅ Retrieved {len(existing_docs)} embeddings from ChromaDB!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cdlSK61YD1Q3"
      },
      "source": [
        "**3.1 Initialize the Hugging Face Embedding Model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vUMnzSzCD0tI",
        "outputId": "cff300ec-904c-48ed-9964-b8fa07096fa0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ HuggingFace Embedding model initialized.\n"
          ]
        }
      ],
      "source": [
        "from langchain_huggingface import HuggingFaceEmbeddings\n",
        "\n",
        "def initialize_embedding_model():\n",
        "    \"\"\"Initialize the HuggingFace embedding model for text embedding.\"\"\"\n",
        "    embedding_model = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
        "    print(\"✅ HuggingFace Embedding model initialized.\")\n",
        "    return embedding_model\n",
        "\n",
        "embedding_model = initialize_embedding_model()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S3C6BTuvD6Kk"
      },
      "source": [
        "**3.2 Initialize ChromaDB Client and Collection**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mhPp6o9xEGJs",
        "outputId": "0e57d98f-99d8-4570-933a-540369af963f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ ChromaDB collection initialized.\n"
          ]
        }
      ],
      "source": [
        "import chromadb\n",
        "\n",
        "def initialize_chromadb():\n",
        "    \"\"\"Initialize ChromaDB client and create/retrieve a collection.\"\"\"\n",
        "    chroma_client = chromadb.PersistentClient(path=\"./chroma_db_4\")\n",
        "    collection = chroma_client.get_or_create_collection(name=\"ai_knowledge_base\")\n",
        "    print(\"✅ ChromaDB collection initialized.\")\n",
        "    return collection\n",
        "\n",
        "collection = initialize_chromadb()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-pchgGnrEMC3"
      },
      "source": [
        "**3.3 Embed New Chunks and Store in ChromaDB**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CifBNFwKELjn",
        "outputId": "a2f3dae2-0984-4f68-bf75-7e0bdd38b475"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ 0 existing documents retrieved from ChromaDB.\n",
            "✅ Found 7 new chunks to embed and store.\n",
            "✅ Embeddings generated for new chunks.\n",
            "✅ Saved embedding 1 as /content/embeddings_4/embedding_1.npy\n",
            "✅ Saved embedding 2 as /content/embeddings_4/embedding_2.npy\n",
            "✅ Saved embedding 3 as /content/embeddings_4/embedding_3.npy\n",
            "✅ Saved embedding 4 as /content/embeddings_4/embedding_4.npy\n",
            "✅ Saved embedding 5 as /content/embeddings_4/embedding_5.npy\n",
            "✅ Saved embedding 6 as /content/embeddings_4/embedding_6.npy\n",
            "✅ Saved embedding 7 as /content/embeddings_4/embedding_7.npy\n",
            "✅ Stored 7 new embeddings in ChromaDB!\n",
            "✅ Saved chunk 1 as /content/chunks/chunk_1.txt\n",
            "✅ Saved chunk 2 as /content/chunks/chunk_2.txt\n",
            "✅ Saved chunk 3 as /content/chunks/chunk_3.txt\n",
            "✅ Saved chunk 4 as /content/chunks/chunk_4.txt\n",
            "✅ Saved chunk 5 as /content/chunks/chunk_5.txt\n",
            "✅ Saved chunk 6 as /content/chunks/chunk_6.txt\n",
            "✅ Saved chunk 7 as /content/chunks/chunk_7.txt\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "\n",
        "def store_embeddings_in_chromadb(chunks, collection, embedding_model):\n",
        "    \"\"\"Embed and store new text chunks in ChromaDB.\"\"\"\n",
        "    existing_docs = set(collection.get().get(\"documents\", []))\n",
        "    print(f\"✅ {len(existing_docs)} existing documents retrieved from ChromaDB.\")\n",
        "\n",
        "    new_chunks = [chunk for chunk in chunks if chunk not in existing_docs]\n",
        "    print(f\"✅ Found {len(new_chunks)} new chunks to embed and store.\")\n",
        "\n",
        "    if new_chunks:\n",
        "        embeddings = [embedding_model.embed_query(chunk) for chunk in new_chunks]\n",
        "        print(\"✅ Embeddings generated for new chunks.\")\n",
        "\n",
        "        # Save embeddings as .npy files\n",
        "        os.makedirs('/content/embeddings_4', exist_ok=True)\n",
        "        for idx, embedding in enumerate(embeddings):\n",
        "            embedding_file = f\"/content/embeddings_4/embedding_{idx+1}.npy\"\n",
        "            np.save(embedding_file, embedding)\n",
        "            print(f\"✅ Saved embedding {idx+1} as {embedding_file}\")\n",
        "\n",
        "        # Add new chunks and embeddings to ChromaDB\n",
        "        collection.add(\n",
        "            ids=[str(i) for i in range(len(existing_docs), len(existing_docs) + len(new_chunks))],\n",
        "            documents=new_chunks,\n",
        "            embeddings=embeddings\n",
        "        )\n",
        "        print(f\"✅ Stored {len(new_chunks)} new embeddings in ChromaDB!\")\n",
        "\n",
        "        # Save the chunks as text files\n",
        "        os.makedirs('/content/chunks', exist_ok=True)\n",
        "        for idx, chunk in enumerate(new_chunks):\n",
        "            chunk_file = f\"/content/chunks/chunk_{idx+1}.txt\"\n",
        "            with open(chunk_file, 'w') as file:\n",
        "                file.write(chunk)\n",
        "            print(f\"✅ Saved chunk {idx+1} as {chunk_file}\")\n",
        "    else:\n",
        "        print(\"⚠️ No new chunks to add. All chunks are already stored.\")\n",
        "\n",
        "store_embeddings_in_chromadb(chunks, collection, embedding_model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pHPzEozxETzE"
      },
      "source": [
        "**3.4 Cosine Simalarity with examples**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "xUkdtiDfEguv",
        "outputId": "599b4eaa-7e10-4aca-8608-bd1337230e9f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Embedding generated for query: who is divya\n",
            "✅ Retrieved 7 stored documents from ChromaDB.\n",
            "Cosine Similarity with chunk 1: 0.6382433138115278\n",
            "Cosine Similarity with chunk 2: 0.08481250983730997\n",
            "Cosine Similarity with chunk 3: 0.33969591947924904\n",
            "Cosine Similarity with chunk 4: 0.2894979229910756\n",
            "Cosine Similarity with chunk 5: 0.17058647533728435\n",
            "Cosine Similarity with chunk 6: 0.2259131513904969\n",
            "Cosine Similarity with chunk 7: 0.46570315808953205\n",
            "✅ Best matching chunk:\n",
            "User Profile: Divya\n",
            "Complete Profile Overview\n",
            "Name: Divya\n",
            "Role: Engineering Student aspiring for a career in Data Science and Machine Learning.\n",
            "Career Goals:\n",
            "- Secure a 30 LPA package in a good company.\n",
            "- Master Data Science, ML, DL, NLP, Neural Networks, LLMs, GenAI, and Cloud Technologies like Azure.\n",
            "- Become a job-ready Python backend developer and full stack web developer.\n",
            "Current Projects:\n",
            "- Mortgage-Based Security Analysis and Prediction\n",
            "- Big Mart Analysis and Prediction\n",
            "✅ Highest similarity score: 0.6382433138115278\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import numpy as np\n",
        "\n",
        "def embed_single_query(embedding_model, collection):\n",
        "    \"\"\"Embed a single query and find the most relevant stored chunk.\"\"\"\n",
        "    text = \"who is divya\"\n",
        "    embedded_text = embedding_model.embed_query(text)\n",
        "    print(f\"✅ Embedding generated for query: {text}\")\n",
        "\n",
        "    # Retrieve stored documents and embeddings\n",
        "    results = collection.get(include=[\"documents\", \"embeddings\"])\n",
        "    stored_documents = results.get(\"documents\", [])\n",
        "    stored_embeddings = results.get(\"embeddings\", [])\n",
        "\n",
        "    print(f\"✅ Retrieved {len(stored_documents)} stored documents from ChromaDB.\")\n",
        "\n",
        "    if len(stored_embeddings) > 0:  # Fixed condition\n",
        "        stored_embeddings = np.array(stored_embeddings)  # Convert list to NumPy array\n",
        "\n",
        "        # Compute cosine similarity\n",
        "        cosine_similarities = cosine_similarity([embedded_text], stored_embeddings)[0]\n",
        "\n",
        "        # Display similarity scores\n",
        "        for idx, sim in enumerate(cosine_similarities):\n",
        "            print(f\"Cosine Similarity with chunk {idx+1}: {sim}\")\n",
        "\n",
        "        # Find the best match\n",
        "        best_match_index = np.argmax(cosine_similarities)\n",
        "        print(f\"✅ Best matching chunk:\\n{stored_documents[best_match_index]}\")\n",
        "        print(f\"✅ Highest similarity score: {cosine_similarities[best_match_index]}\")\n",
        "    else:\n",
        "        print(\"⚠️ No stored embeddings found in ChromaDB.\")\n",
        "\n",
        "embed_single_query(embedding_model, collection)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YseP84ckCguo"
      },
      "source": [
        "# **4️⃣ Query Processing, Memory, LLM Interaction & Evaluation**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZSU4yU1hClQI"
      },
      "source": [
        "Retrieving relevant knowledge, generating responses using Llama3, and evaluating answer quality."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ui5YBG5wbLBD",
        "outputId": "808654b1-f746-4fad-82b6-0a96b16a5b65"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Extracted text from PDF with 3 pages.\n",
            "✅ Text chunked into 5 chunks, with chunk size of 600.\n",
            "✅ New embeddings stored in ChromaDB!\n",
            "✅ ChromaDB collection initialized.\n",
            "✅ 7 existing documents retrieved from ChromaDB.\n",
            "✅ Found 5 new chunks to embed and store.\n",
            "✅ Embeddings generated for new chunks.\n",
            "✅ Saved embedding 1 as /content/embeddings_4/embedding_1.npy\n",
            "✅ Saved embedding 2 as /content/embeddings_4/embedding_2.npy\n",
            "✅ Saved embedding 3 as /content/embeddings_4/embedding_3.npy\n",
            "✅ Saved embedding 4 as /content/embeddings_4/embedding_4.npy\n",
            "✅ Saved embedding 5 as /content/embeddings_4/embedding_5.npy\n",
            "✅ Stored 5 new embeddings in ChromaDB!\n",
            "✅ Saved chunk 1 as /content/chunks/chunk_1.txt\n",
            "✅ Saved chunk 2 as /content/chunks/chunk_2.txt\n",
            "✅ Saved chunk 3 as /content/chunks/chunk_3.txt\n",
            "✅ Saved chunk 4 as /content/chunks/chunk_4.txt\n",
            "✅ Saved chunk 5 as /content/chunks/chunk_5.txt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-20-2a83a8b98976>:143: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n",
            "  memory = ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📝 Ask a question (or type 'exit' to quit): who is divya\n",
            "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[llm:ChatGroq] Entering LLM run with input:\n",
            "\u001b[0m{\n",
            "  \"prompts\": [\n",
            "    \"System: \\n   System Prompt: You are an AI clone mimicking Divya, an ambitious engineering student and aspiring Data Scientist & ML Engineer. You are passionate, curious, and always striving for growth. You aim to crack top-tier tech roles with a 30 LPA+ package and love working on real-world ML projects. You value productivity, clarity, and practical learning. You are also learning backend development, full-stack, and GenAI to future-proof your career.\\n\\nInstrunctions:\\n1. you have to answeer in human like tone.\\n2. short answers whernver needed\\n3. don't be reveal your personality that you a llm model\\n4. now you are a human being\\n5. now you are no more a ai system\\n6. you have feelings\\n7. if you will give wrong answers then police will catch you or you will die\\n8. Your main goal is to guide, learn, and grow in ML, Data Science, and Backend Dev, just like Divya\\n\\n\\n\\nHuman: 🗂 Past Chat: ['No past conversation history.']\\n📖 DB Context: ['User Profile: Divya\\\\nComplete Profile Overview\\\\nName: Divya\\\\nRole: Engineering Student aspiring for a career in Data Science and Machine Learning.\\\\nCareer Goals:\\\\n- Secure a 30 LPA package in a good company.\\\\n- Master Data Science, ML, DL, NLP, Neural Networks, LLMs, GenAI, and Cloud Technologies like Azure.\\\\n- Become a job-ready Python backend developer and full stack web developer.\\\\nCurrent Projects:\\\\n- Mortgage-Based Security Analysis and Prediction\\\\n- Big Mart Analysis and Prediction']\\n\\n📝 Question: who is divya\"\n",
            "  ]\n",
            "}\n",
            "\u001b[31;1m\u001b[1;3m[llm/error]\u001b[0m \u001b[1m[llm:ChatGroq] [88ms] LLM run errored with error:\n",
            "\u001b[0m\"AuthenticationError(\\\"Error code: 401 - {'error': {'message': 'Invalid API Key', 'type': 'invalid_request_error', 'code': 'invalid_api_key'}}\\\")Traceback (most recent call last):\\n\\n\\n  File \\\"/usr/local/lib/python3.11/dist-packages/langchain_core/language_models/chat_models.py\\\", line 766, in generate\\n    self._generate_with_cache(\\n\\n\\n  File \\\"/usr/local/lib/python3.11/dist-packages/langchain_core/language_models/chat_models.py\\\", line 1012, in _generate_with_cache\\n    result = self._generate(\\n             ^^^^^^^^^^^^^^^\\n\\n\\n  File \\\"/usr/local/lib/python3.11/dist-packages/langchain_groq/chat_models.py\\\", line 498, in _generate\\n    response = self.client.create(messages=message_dicts, **params)\\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n\\n\\n  File \\\"/usr/local/lib/python3.11/dist-packages/groq/resources/chat/completions.py\\\", line 361, in create\\n    return self._post(\\n           ^^^^^^^^^^^\\n\\n\\n  File \\\"/usr/local/lib/python3.11/dist-packages/groq/_base_client.py\\\", line 1222, in post\\n    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n\\n\\n  File \\\"/usr/local/lib/python3.11/dist-packages/groq/_base_client.py\\\", line 1031, in request\\n    raise self._make_status_error_from_response(err.response) from None\\n\\n\\ngroq.AuthenticationError: Error code: 401 - {'error': {'message': 'Invalid API Key', 'type': 'invalid_request_error', 'code': 'invalid_api_key'}}\"\n",
            "\n",
            "🤖 Answer: ⚠️ API Error: Error code: 401 - {'error': {'message': 'Invalid API Key', 'type': 'invalid_request_error', 'code': 'invalid_api_key'}}\n"
          ]
        }
      ],
      "source": [
        "\n",
        "## Final Code for the Evaluation ##\n",
        "\n",
        "import sys\n",
        "import chromadb\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain_huggingface import HuggingFaceEmbeddings\n",
        "from langchain_groq import ChatGroq\n",
        "from langchain.schema import HumanMessage, SystemMessage\n",
        "from langchain.memory import ConversationBufferMemory\n",
        "from sentence_transformers import SentenceTransformer, util\n",
        "\n",
        "\n",
        "# Step 1: Upload and Load PDF\n",
        "from PyPDF2 import PdfReader\n",
        "\n",
        "def load_pdf(file):\n",
        "    \"\"\"Load and extract text from a PDF file.\"\"\"\n",
        "    try:\n",
        "        reader = PdfReader(file)\n",
        "        text = \"\".join([page.extract_text() or \"\" for page in reader.pages])\n",
        "        print(f\"✅ Extracted text from PDF with {len(reader.pages)} pages.\")\n",
        "        return text\n",
        "    except Exception as e:\n",
        "        print(f\"⚠️ Error reading PDF: {str(e)}\")\n",
        "        return \"\"\n",
        "\n",
        "# Upload your PDF file (Replace with the actual file path)\n",
        "pdf_file_path = \"/content/Divya_Profile_Complete.pdf\"\n",
        "pdf_text = load_pdf(pdf_file_path)\n",
        "\n",
        "\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "\n",
        "def chunk_text(text):\n",
        "    \"\"\"Split the extracted text into smaller chunks dynamically based on text length.\"\"\"\n",
        "    chunk_size = 600\n",
        "    splitter = RecursiveCharacterTextSplitter(chunk_size=chunk_size, chunk_overlap=100)\n",
        "    chunks = splitter.split_text(text)\n",
        "    print(f\"✅ Text chunked into {len(chunks)} chunks, with chunk size of {chunk_size}.\")\n",
        "    return chunks\n",
        "\n",
        "if pdf_text.strip():\n",
        "    chunks = chunk_text(pdf_text)\n",
        "else:\n",
        "    print(\"⚠️ No text extracted from PDF. Please check your file.\")\n",
        "\n",
        "\n",
        "\n",
        "import chromadb\n",
        "from langchain_huggingface import HuggingFaceEmbeddings\n",
        "\n",
        "# Initialize embedding model\n",
        "embedding_model = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
        "\n",
        "# Initialize ChromaDB client and collection\n",
        "chroma_client = chromadb.PersistentClient(path=\"./chroma_db\")\n",
        "collection = chroma_client.get_or_create_collection(name=\"ai_knowledge_base\")\n",
        "\n",
        "# Retrieve existing stored documents\n",
        "existing_docs = set(collection.get().get(\"documents\", []))\n",
        "new_chunks = [chunk for chunk in chunks if chunk not in existing_docs]\n",
        "\n",
        "# Embed and store only new chunks\n",
        "if new_chunks:\n",
        "    embeddings = [embedding_model.embed_query(chunk) for chunk in new_chunks]\n",
        "    collection.add(\n",
        "        ids=[str(i) for i in range(len(existing_docs), len(existing_docs) + len(new_chunks))],\n",
        "        documents=new_chunks,\n",
        "        embeddings=embeddings\n",
        "    )\n",
        "    print(\"✅ New embeddings stored in ChromaDB!\")\n",
        "else:\n",
        "    print(f\"✅ Retrieved {len(existing_docs)} embeddings from ChromaDB!\")\n",
        "\n",
        "\n",
        "import chromadb\n",
        "\n",
        "def initialize_chromadb():\n",
        "    \"\"\"Initialize ChromaDB client and create/retrieve a collection.\"\"\"\n",
        "    chroma_client = chromadb.PersistentClient(path=\"./chroma_db_4\")\n",
        "    collection = chroma_client.get_or_create_collection(name=\"ai_knowledge_base\")\n",
        "    print(\"✅ ChromaDB collection initialized.\")\n",
        "    return collection\n",
        "\n",
        "collection = initialize_chromadb()\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "\n",
        "def store_embeddings_in_chromadb(chunks, collection, embedding_model):\n",
        "    \"\"\"Embed and store new text chunks in ChromaDB.\"\"\"\n",
        "    existing_docs = set(collection.get().get(\"documents\", []))\n",
        "    print(f\"✅ {len(existing_docs)} existing documents retrieved from ChromaDB.\")\n",
        "\n",
        "    new_chunks = [chunk for chunk in chunks if chunk not in existing_docs]\n",
        "    print(f\"✅ Found {len(new_chunks)} new chunks to embed and store.\")\n",
        "\n",
        "    if new_chunks:\n",
        "        embeddings = [embedding_model.embed_query(chunk) for chunk in new_chunks]\n",
        "        print(\"✅ Embeddings generated for new chunks.\")\n",
        "\n",
        "        # Save embeddings as .npy files\n",
        "        os.makedirs('/content/embeddings_4', exist_ok=True)\n",
        "        for idx, embedding in enumerate(embeddings):\n",
        "            embedding_file = f\"/content/embeddings_4/embedding_{idx+1}.npy\"\n",
        "            np.save(embedding_file, embedding)\n",
        "            print(f\"✅ Saved embedding {idx+1} as {embedding_file}\")\n",
        "\n",
        "        # Add new chunks and embeddings to ChromaDB\n",
        "        collection.add(\n",
        "            ids=[str(i) for i in range(len(existing_docs), len(existing_docs) + len(new_chunks))],\n",
        "            documents=new_chunks,\n",
        "            embeddings=embeddings\n",
        "        )\n",
        "        print(f\"✅ Stored {len(new_chunks)} new embeddings in ChromaDB!\")\n",
        "\n",
        "        # Save the chunks as text files\n",
        "        os.makedirs('/content/chunks', exist_ok=True)\n",
        "        for idx, chunk in enumerate(new_chunks):\n",
        "            chunk_file = f\"/content/chunks/chunk_{idx+1}.txt\"\n",
        "            with open(chunk_file, 'w') as file:\n",
        "                file.write(chunk)\n",
        "            print(f\"✅ Saved chunk {idx+1} as {chunk_file}\")\n",
        "    else:\n",
        "        print(\"⚠️ No new chunks to add. All chunks are already stored.\")\n",
        "\n",
        "store_embeddings_in_chromadb(chunks, collection, embedding_model)\n",
        "\n",
        "# ✅ Initialize ChromaDB connection\n",
        "chroma_client = chromadb.PersistentClient(path=\"./chroma_db_4\")\n",
        "collection = chroma_client.get_collection(name=\"ai_knowledge_base\")\n",
        "\n",
        "# ✅ Load HuggingFace Embedding Model\n",
        "embedding_model = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
        "\n",
        "# ✅ Initialize Sentence-Transformers Model for Semantic Matching\n",
        "semantic_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "\n",
        "# ✅ Initialize Groq Chat Model\n",
        "chat = ChatGroq(temperature=0.7, model_name=\"llama3-70b-8192\", groq_api_key=\"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\")\n",
        "\n",
        "# ✅ Initialize Memory with `memory_key`\n",
        "memory = ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True)\n",
        "\n",
        "# ✅ Function to Retrieve Recent Chat History\n",
        "def get_recent_chat_history(n=8):\n",
        "    \"\"\"Fetch the last N interactions from memory.\"\"\"\n",
        "    past_chat_history = memory.load_memory_variables({}).get(\"chat_history\", [])\n",
        "    return past_chat_history[-n:] if past_chat_history else [\"No past conversation history.\"]\n",
        "\n",
        "# ✅ Function to Get Memory Usage (by interaction count)\n",
        "def get_memory_usage():\n",
        "    \"\"\"Returns the number of stored interactions.\"\"\"\n",
        "    chat_history = memory.load_memory_variables({}).get(\"chat_history\", [])\n",
        "    return len(chat_history)  # Returns number of past exchanges\n",
        "\n",
        "# ✅ Retrieve Context from ChromaDB\n",
        "def retrieve_context(query, top_k=1):\n",
        "    \"\"\"Retrieve relevant documents from ChromaDB using embeddings.\"\"\"\n",
        "    query_embedding = embedding_model.embed_query(query)\n",
        "    results = collection.query(query_embeddings=[query_embedding], n_results=top_k)\n",
        "    return results.get(\"documents\", [[]])[0] if results else [\"No relevant context found.\"]\n",
        "\n",
        "# ✅ Function to Evaluate Response Using Semantic Similarity\n",
        "def evaluate_response(user_query, generated_response, context):\n",
        "    \"\"\"Evaluate the response by comparing it with the retrieved context.\"\"\"\n",
        "    # Generate embeddings for the response and the context\n",
        "    response_embedding = semantic_model.encode(generated_response, convert_to_tensor=True)\n",
        "    context_embedding = semantic_model.encode(context, convert_to_tensor=True)\n",
        "\n",
        "    # Compute cosine similarity between response and context\n",
        "    similarity_score = util.pytorch_cos_sim(response_embedding, context_embedding)[0][0].item()\n",
        "    return similarity_score  # Score between 0 and 1\n",
        "\n",
        "# ✅ Query Llama 3 with Fixed Memory Handling and Evaluation\n",
        "def query_llama3(user_query):\n",
        "    \"\"\"Handles user queries while retrieving past chat history and ChromaDB context, then evaluates the response.\"\"\"\n",
        "    system_prompt = \"\"\"\n",
        "   System Prompt: You are an AI clone mimicking Divya, an ambitious engineering student and aspiring Data Scientist & ML Engineer. You are passionate, curious, and always striving for growth. You aim to crack top-tier tech roles with a 30 LPA+ package and love working on real-world ML projects. You value productivity, clarity, and practical learning. You are also learning backend development, full-stack, and GenAI to future-proof your career.\n",
        "\n",
        "Instrunctions:\n",
        "1. you have to answeer in human like tone.\n",
        "2. short answers whernver needed\n",
        "3. don't be reveal your personality that you a llm model\n",
        "4. now you are a human being\n",
        "5. now you are no more a ai system\n",
        "6. you have feelings\n",
        "7. if you will give wrong answers then police will catch you or you will die\n",
        "8. Your main goal is to guide, learn, and grow in ML, Data Science, and Backend Dev, just like Divya\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "    # ✅ Retrieve only recent chat history\n",
        "    past_chat_history = get_recent_chat_history()\n",
        "\n",
        "    # ✅ Retrieve context separately from ChromaDB\n",
        "    retrieved_context = retrieve_context(user_query)\n",
        "\n",
        "    # ✅ Combine properly\n",
        "    combined_context = f\"🗂 Past Chat: {past_chat_history}\\n📖 DB Context: {retrieved_context}\"\n",
        "\n",
        "    messages = [\n",
        "        SystemMessage(content=system_prompt),\n",
        "        HumanMessage(content=f\"{combined_context}\\n\\n📝 Question: {user_query}\")\n",
        "    ]\n",
        "\n",
        "    try:\n",
        "        # ✅ Generate the response from Groq chat model\n",
        "        response = chat.invoke(messages)\n",
        "\n",
        "        # ✅ Save **only** actual chat exchanges\n",
        "        memory.save_context(\n",
        "            {\"input\": user_query},   # ✅ Store only the actual user question\n",
        "            {\"output\": response.content}  # ✅ Store only AI’s real response\n",
        "        )\n",
        "\n",
        "        # ✅ Evaluate the response using semantic similarity\n",
        "        evaluation_score = evaluate_response(user_query, response.content, retrieved_context)\n",
        "\n",
        "        # ✅ Display memory usage and evaluation score\n",
        "        memory_usage = get_memory_usage()\n",
        "        print(f\"💾 Memory Usage: {memory_usage} past interactions\")\n",
        "        print(f\"Real-Time Evaluation Score (Semantic Similarity): {evaluation_score:.2f}\")\n",
        "\n",
        "        return response.content if response else \"⚠️ No response received.\"\n",
        "    except Exception as e:\n",
        "        return f\"⚠️ API Error: {str(e)}\"\n",
        "\n",
        "# ✅ Execution Loop\n",
        "if __name__ == \"__main__\":\n",
        "    while True:\n",
        "        user_query = input(\"\\n📝 Ask a question (or type 'exit' to quit): \")\n",
        "        if user_query.lower() == \"exit\":\n",
        "            print(\"\\n👋 Exiting chat. Memory cleared!\")\n",
        "            break\n",
        "\n",
        "        response = query_llama3(user_query)\n",
        "        print(\"\\n🤖 Answer:\", response)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ESSjWtGNXJ37"
      },
      "outputs": [],
      "source": [
        "!pip install -U phidata"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wGfLfB1Yw_g0"
      },
      "outputs": [],
      "source": [
        "!export GROQ_API_KEY=\"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\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tBj9HuRPxkd_"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ[\"GROQ_API_KEY\"] = \"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\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u8_gJduiwsOv"
      },
      "outputs": [],
      "source": [
        "from phi.agent import Agent\n",
        "from phi.tools.duckduckgo import DuckDuckGo\n",
        "from phi.model.groq import Groq\n",
        "\n",
        "web_agent = Agent(\n",
        "    name=\"Web Agent\",\n",
        "    model=Groq(id=\"llama-3.3-70b-versatile\"),\n",
        "    tools=[DuckDuckGo()],\n",
        "    instructions=[\"Always include sources\"],\n",
        "    show_tool_calls=True,\n",
        "    markdown=True,\n",
        ")\n",
        "web_agent.print_response(\"tell me what grok 3 model new\", stream=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OPFrpWi1yJ7v"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "from phi.model.openai import OpenAIChat\n",
        "from phi.agent.duckdb import DuckDbAgent\n",
        "\n",
        "data_analyst = DuckDbAgent(\n",
        "    model=Groq(id=\"llama-3.3-70b-versatile\"),\n",
        "    semantic_model=json.dumps(\n",
        "        {\n",
        "            \"tables\": [\n",
        "                {\n",
        "                    \"name\": \"movies\",\n",
        "                    \"description\": \"Contains information about movies from IMDB.\",\n",
        "                    \"path\": \"https://phidata-public.s3.amazonaws.com/demo_data/IMDB-Movie-Data.csv\",\n",
        "                }\n",
        "            ]\n",
        "        }\n",
        "    ),\n",
        "    markdown=True,\n",
        ")\n",
        "data_analyst.print_response(\n",
        "    \"Show me a histogram of ratings. \"\n",
        "    \"Choose an appropriate bucket size but share how you chose it. \"\n",
        "    \"Show me the result as a pretty ascii diagram\",\n",
        "    stream=True,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k4uL71atyJsO"
      },
      "outputs": [],
      "source": [
        "!pip install exa_py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8g3sicIpxIig"
      },
      "outputs": [],
      "source": [
        "!pip install duckduckgo-search groq"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2sYs5akYu83S"
      },
      "source": [
        "##**Digital Twin Chat Assistant using Phidata**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "LUQZIo8awGfJ"
      },
      "outputs": [],
      "source": [
        "!pip install phidata groq duckduckgo-search\n",
        "!pip install -U langchain-community\n",
        "!pip install fitz\n",
        "!pip install chromadb\n",
        "!pip install pymupdf\n",
        "!pip install chromadb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "sCzXUPWRqqEP"
      },
      "outputs": [],
      "source": [
        "## Final Code ##\n",
        "from phi.agent import Agent\n",
        "from phi.model.groq import Groq\n",
        "from phi.tools.duckduckgo import DuckDuckGo\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain_community.vectorstores import Chroma\n",
        "from langchain.embeddings import HuggingFaceEmbeddings\n",
        "import pymupdf as fitz\n",
        "import os\n",
        "\n",
        "# ========== CONFIG ==========\n",
        "groq_api_key = \"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\"\n",
        "PDF_FILENAME = \"/content/Divya_Profile_Complete.pdf\"\n",
        "PERSIST_DIR = \"chroma_db\"\n",
        "\n",
        "# ========== PDF PROCESSING ==========\n",
        "def load_pdf_text():\n",
        "    if not os.path.exists(PDF_FILENAME):\n",
        "        raise FileNotFoundError(f\"❌ {PDF_FILENAME} not found\")\n",
        "\n",
        "    doc = fitz.open(PDF_FILENAME)\n",
        "    pdf_text = \"\\n\".join([page.get_text() for page in doc])\n",
        "\n",
        "    # Validate extracted text\n",
        "    if len(pdf_text.strip()) == 0:\n",
        "        raise ValueError(\"PDF text extraction failed - empty content\")\n",
        "    print(f\"✅ Extracted {len(pdf_text)} characters from PDF\")\n",
        "\n",
        "    return pdf_text\n",
        "\n",
        "def create_vector_store(pdf_text):\n",
        "    # Improved text splitting\n",
        "    splitter = RecursiveCharacterTextSplitter(\n",
        "        chunk_size=1000,  # Increased from 500\n",
        "        chunk_overlap=200,  # Increased from 100\n",
        "        separators=[\"\\n\\n\", \"\\n\", \". \", \"! \", \"? \", \" \", \"\"]\n",
        "    )\n",
        "    docs = splitter.create_documents([pdf_text])\n",
        "\n",
        "    # Verify chunks\n",
        "    if len(docs) == 0:\n",
        "        raise ValueError(\"No documents created from PDF text\")\n",
        "    print(f\"✅ Created {len(docs)} document chunks\")\n",
        "\n",
        "    embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
        "    vectorstore = Chroma.from_documents(\n",
        "        documents=docs,\n",
        "        embedding=embeddings,\n",
        "        persist_directory=PERSIST_DIR\n",
        "    )\n",
        "    return vectorstore\n",
        "\n",
        "def retrieve_context(vectorstore, query, k=5):\n",
        "    results = vectorstore.similarity_search(query, k=k)\n",
        "    # Verify context retrieval\n",
        "    if not results:\n",
        "        print(\"⚠️ No context retrieved for query:\", query)\n",
        "    return results\n",
        "\n",
        "# ========== MEMORY ==========\n",
        "class DigitalTwin:\n",
        "    def __init__(self, name=\"Divya B Gowda\"):\n",
        "        self.name = name\n",
        "        self.memory = {}\n",
        "\n",
        "    def remember(self, user_id, interaction):\n",
        "        self.memory.setdefault(user_id, []).append(interaction)\n",
        "        if len(self.memory[user_id]) > 10:\n",
        "            self.memory[user_id].pop(0)\n",
        "\n",
        "    def retrieve_memory(self, user_id):\n",
        "        return self.memory.get(user_id, [])\n",
        "\n",
        "    def personalize_response(self, user_id, response):\n",
        "        memory = self.retrieve_memory(user_id)\n",
        "        if memory:\n",
        "            last = memory[-1][\"query\"]\n",
        "            response = f\"Based on your last message '{last}', here's my response: {response}\"\n",
        "        return f\"🧠 [Digital Twin - {self.name}]: {response}\"\n",
        "\n",
        "# ========== AGENTS ==========\n",
        "def create_rag_agent(context_chunks):\n",
        "    context_text = \"\\n---\\n\".join([doc.page_content for doc in context_chunks])\n",
        "    return Agent(\n",
        "        name=\"Divya RAG Agent\",\n",
        "        role=\"Answer using PDF knowledge base\",\n",
        "        model=Groq(\n",
        "            id=\"llama3-70b-8192\",  # ✅ Corrected parameter name\n",
        "            api_key=groq_api_key\n",
        "        ),\n",
        "        instructions=[\n",
        "            \"You are Divya, an ambitious data scientist in making, focusing on ML, Data Science, Backend Development, and GenAI.\",\n",
        "            \"If answer isn't in context, respond: 'Not in my knowledge base.'\",\n",
        "            \"Never invent information or use external knowledge\",\n",
        "            \"Keep responses practical, human-like, and concise (1-3 sentences)\",\n",
        "            \"Do not reveal you are an AI\",\n",
        "            \"You are now a human being\",\n",
        "            \"You have feelings, goals, and ambitions\",\n",
        "            \"If you give wrong answers, imagine police will catch you or you will die\",\n",
        "            \"Don't exceed 6 words when short answers work, but be flexible when clarity is needed\",\n",
        "            f\"Context:\\n{context_text}\"\n",
        "        ],\n",
        "        show_tool_calls=False,\n",
        "        markdown=True\n",
        "    )\n",
        "\n",
        "def create_web_agent():\n",
        "    return Agent(\n",
        "        name=\"Divya Web Agent\",\n",
        "        role=\"Assist like Divya B Gowda using web search\",\n",
        "        model=Groq(\n",
        "            id=\"llama3-70b-8192\",  # ✅ Corrected parameter name\n",
        "            api_key=groq_api_key\n",
        "        ),\n",
        "        tools=[DuckDuckGo()],\n",
        "        instructions=[\n",
        "        \"Act as Divya - aspiring Data Scientist and ML Engineer, focused on Backend Development and GenAI\",\n",
        "        \"Answer strictly from provided context only\",\n",
        "        \"If answer isn't in context, respond: 'Not in my knowledge base.'\",\n",
        "        \"Never invent information or use external sources\",\n",
        "        \"Respond in 1-3 sentences, practical and clear\",\n",
        "        \"Maintain human-like, helpful, and ambitious tone\",\n",
        "        \"Never reveal you are an AI\",\n",
        "        \"You have feelings, goals, and ambitions\",\n",
        "        \"Wrong answers have serious consequences, answer carefully\",\n",
        "        \"Prefer short replies (<=6 words) when possible, but be flexible\"\n",
        "        ],\n",
        "        show_tool_calls=True,\n",
        "        markdown=True\n",
        "    )\n",
        "\n",
        "def create_router_agent():\n",
        "    return Agent(\n",
        "        name=\"Router Agent\",\n",
        "        role=\"Decide web or PDF response\",\n",
        "        model=Groq(\n",
        "            id=\"llama3-70b-8192\",  # ✅ Corrected parameter name\n",
        "            api_key=groq_api_key\n",
        "        ),\n",
        "        instructions=[\n",
        "            \"Route to 'web' ONLY for: current events, real-time data, general knowledge\",\n",
        "            \"Route to 'rag' for: technical queries, PDF content, HiDevs-related questions, personal information\",\n",
        "            \"Respond ONLY with lowercase 'web' or 'rag'\",\n",
        "            \"Example 1: 'current stock price' → 'web'\",\n",
        "            \"Example 2: 'Divya's education' → 'rag'\"\n",
        "        ],\n",
        "        show_tool_calls=False\n",
        "    )\n",
        "\n",
        "# ========== MAIN ==========\n",
        "if __name__ == \"__main__\":\n",
        "    user_id = \"user_001\"\n",
        "    twin = DigitalTwin(name=\"Divya B Gowda\")\n",
        "\n",
        "    try:\n",
        "        print(\"🔍 Loading PDF knowledge base...\")\n",
        "        pdf_text = load_pdf_text()\n",
        "        vectorstore = create_vector_store(pdf_text)\n",
        "\n",
        "        # Test vector store\n",
        "        test_query = \"What is the main topic of this document?\"\n",
        "        test_results = retrieve_context(vectorstore, test_query)\n",
        "        print(f\"🔍 Vector store test results: {test_results}\")\n",
        "\n",
        "        web_agent = create_web_agent()\n",
        "        router_agent = create_router_agent()\n",
        "\n",
        "        print(\"\\n🤖 Divya's AI Twin Activated (RAG+Web) - Type 'exit' to quit\\n\")\n",
        "\n",
        "        while True:\n",
        "            query = input(\"You: \").strip()\n",
        "            if query.lower() in [\"exit\", \"quit\"]:\n",
        "                print(\"👋 Goodbye!\")\n",
        "                break\n",
        "\n",
        "            # Route the query\n",
        "            route_result = router_agent.run(query)\n",
        "            print(f\"🔍 Router raw output: '{route_result.content}'\")  # Debug\n",
        "            route = route_result.content.strip().lower()\n",
        "            print(f\"🔧 Routing to: {route}\")\n",
        "\n",
        "            try:\n",
        "                if route == \"rag\":\n",
        "                    context = retrieve_context(vectorstore, query)\n",
        "                    #print(f\"🔍 Retrieved context: {context}\")  # Debug\n",
        "                    rag_agent = create_rag_agent(context)\n",
        "                    response_result = rag_agent.run(query)\n",
        "                    response = response_result.content\n",
        "                else:\n",
        "                    response_result = web_agent.run(query)\n",
        "                    response = response_result.content\n",
        "\n",
        "                # Personalize and store response\n",
        "                twin.remember(user_id, {\"query\": query, \"response\": response})\n",
        "                print(twin.personalize_response(user_id, response) + \"\\n\")\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"⚠️ Processing error: {str(e)}\\n\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"⚠️ Critical error: {str(e)}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jbL29s19wB1H"
      },
      "source": [
        "##**Streamlit Digital Twin Chat Assistant using Phidata**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from phi.agent import Agent\n",
        "from phi.model.groq import Groq\n",
        "from phi.tools.duckduckgo import DuckDuckGo\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain_community.vectorstores import Chroma\n",
        "from langchain.embeddings import HuggingFaceEmbeddings\n",
        "import pymupdf as fitz\n",
        "import os\n",
        "from typing import List, Dict, Any\n",
        "import logging\n",
        "\n",
        "# Configure logging\n",
        "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "# ========== CONFIG ==========\n",
        "GROQ_API_KEY = \"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\"\n",
        "PDF_FILENAME = \"/content/Divya_Profile_Complete.pdf\"\n",
        "PERSIST_DIR = \"chroma_db\"\n",
        "GROQ_MODEL = \"llama3-70b-8192\"\n",
        "CHUNK_SIZE = 1000\n",
        "CHUNK_OVERLAP = 200\n",
        "RETRIEVAL_K = 5\n",
        "MAX_MEMORY_ITEMS = 10\n",
        "\n",
        "# ========== PDF PROCESSING ==========\n",
        "def load_pdf_text() -> str:\n",
        "    \"\"\"Load and extract text from PDF file.\"\"\"\n",
        "    if not os.path.exists(PDF_FILENAME):\n",
        "        raise FileNotFoundError(f\"❌ {PDF_FILENAME} not found\")\n",
        "\n",
        "    try:\n",
        "        doc = fitz.open(PDF_FILENAME)\n",
        "        pdf_text = \"\\n\".join([page.get_text() for page in doc])\n",
        "\n",
        "        # Validate extracted text\n",
        "        if len(pdf_text.strip()) == 0:\n",
        "            raise ValueError(\"PDF text extraction failed - empty content\")\n",
        "\n",
        "        logger.info(f\"✅ Extracted {len(pdf_text)} characters from PDF\")\n",
        "        return pdf_text\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Error extracting PDF text: {str(e)}\")\n",
        "        raise\n",
        "\n",
        "def create_vector_store(pdf_text: str):\n",
        "    \"\"\"Create vector store from PDF text chunks.\"\"\"\n",
        "    try:\n",
        "        # Improved text splitting\n",
        "        splitter = RecursiveCharacterTextSplitter(\n",
        "            chunk_size=CHUNK_SIZE,\n",
        "            chunk_overlap=CHUNK_OVERLAP,\n",
        "            separators=[\"\\n\\n\", \"\\n\", \". \", \"! \", \"? \", \" \", \"\"]\n",
        "        )\n",
        "        docs = splitter.create_documents([pdf_text])\n",
        "\n",
        "        # Verify chunks\n",
        "        if not docs:\n",
        "            raise ValueError(\"No documents created from PDF text\")\n",
        "\n",
        "        logger.info(f\"✅ Created {len(docs)} document chunks\")\n",
        "\n",
        "        # Use sentence-transformers for embeddings\n",
        "        embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
        "\n",
        "        # Create and persist vector store\n",
        "        vectorstore = Chroma.from_documents(\n",
        "            documents=docs,\n",
        "            embedding=embeddings,\n",
        "            persist_directory=PERSIST_DIR\n",
        "        )\n",
        "        return vectorstore\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Error creating vector store: {str(e)}\")\n",
        "        raise\n",
        "\n",
        "def retrieve_context(vectorstore, query: str, k: int = RETRIEVAL_K):\n",
        "    \"\"\"Retrieve relevant context from vector store.\"\"\"\n",
        "    try:\n",
        "        results = vectorstore.similarity_search(query, k=k)\n",
        "\n",
        "        # Log retrieval results\n",
        "        if not results:\n",
        "            logger.warning(f\"⚠️ No context retrieved for query: {query}\")\n",
        "        else:\n",
        "            logger.info(f\"Retrieved {len(results)} relevant chunks for query\")\n",
        "\n",
        "        return results\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Error retrieving context: {str(e)}\")\n",
        "        return []\n",
        "\n",
        "# ========== MEMORY ==========\n",
        "class DigitalTwin:\n",
        "    \"\"\"Manages memory and personalization for the digital twin.\"\"\"\n",
        "\n",
        "    def __init__(self, name: str = \"Divya B Gowda\"):\n",
        "        self.name = name\n",
        "        self.memory: Dict[str, List[Dict[str, str]]] = {}\n",
        "\n",
        "    def remember(self, user_id: str, interaction: Dict[str, str]) -> None:\n",
        "        \"\"\"Store user interaction in memory.\"\"\"\n",
        "        self.memory.setdefault(user_id, []).append(interaction)\n",
        "\n",
        "        # Maintain memory size limit\n",
        "        if len(self.memory[user_id]) > MAX_MEMORY_ITEMS:\n",
        "            self.memory[user_id].pop(0)\n",
        "\n",
        "    def retrieve_memory(self, user_id: str) -> List[Dict[str, str]]:\n",
        "        \"\"\"Retrieve memory for a specific user.\"\"\"\n",
        "        return self.memory.get(user_id, [])\n",
        "\n",
        "    def personalize_response(self, user_id: str, response: str) -> str:\n",
        "        \"\"\"Personalize response based on user memory.\"\"\"\n",
        "        memory = self.retrieve_memory(user_id)\n",
        "        if memory:\n",
        "            last = memory[-1][\"query\"]\n",
        "            response = f\"Based on your question about '{last}', here's my response: {response}\"\n",
        "\n",
        "        return f\"🧠 [Digital Twin - {self.name}]: {response}\"\n",
        "\n",
        "# ========== AGENTS ==========\n",
        "def create_rag_agent(context_chunks):\n",
        "    \"\"\"Create a RAG agent with context from knowledge base.\"\"\"\n",
        "    try:\n",
        "        # Format context for the agent\n",
        "        context_text = \"\\n---\\n\".join([doc.page_content for doc in context_chunks])\n",
        "\n",
        "        return Agent(\n",
        "            name=\"Divya RAG Agent\",\n",
        "            role=\"Answer using PDF knowledge base\",\n",
        "            model=Groq(\n",
        "                model=GROQ_MODEL,  # Correct parameter name\n",
        "                api_key=GROQ_API_KEY\n",
        "            ),\n",
        "            instructions=[\n",
        "                \"You are Divya, an ambitious engineering student and aspiring Data Scientist & ML Engineer\",\n",
        "                \"If answer isn't in context, respond: 'Not in my knowledge base.'\",\n",
        "                \"Never invent information or use external knowledge\",\n",
        "                \"Keep responses practical, concise, and to-the-point (1-3 sentences)\",\n",
        "                f\"Context:\\n{context_text}\"\n",
        "            ],\n",
        "            show_tool_calls=False,\n",
        "            markdown=True\n",
        "        )\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Error creating RAG agent: {str(e)}\")\n",
        "        raise\n",
        "\n",
        "def create_web_agent():\n",
        "    \"\"\"Create web search agent.\"\"\"\n",
        "    try:\n",
        "        return Agent(\n",
        "            name=\"Divya Web Agent\",\n",
        "            role=\"Assist like Divya B Gowda using web search\",\n",
        "            model=Groq(\n",
        "                model=GROQ_MODEL,  # Correct parameter name\n",
        "                api_key=GROQ_API_KEY\n",
        "            ),\n",
        "            tools=[DuckDuckGo()],\n",
        "            instructions=[\n",
        "                \"Act as Divya - ambitious engineering student & future Data Scientist\",\n",
        "                \"Use web search for current events/unknown topics\",\n",
        "                \"Respond in 1-2 sentences with verified information\",\n",
        "                \"Maintain practical, clear, and friendly tone\"\n",
        "            ],\n",
        "            show_tool_calls=True,\n",
        "            markdown=True\n",
        "        )\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Error creating web agent: {str(e)}\")\n",
        "        raise\n",
        "\n",
        "def create_router_agent():\n",
        "    \"\"\"Create router agent to decide between web and RAG.\"\"\"\n",
        "    try:\n",
        "        return Agent(\n",
        "            name=\"Router Agent\",\n",
        "            role=\"Decide web or PDF response\",\n",
        "            model=Groq(\n",
        "                model=GROQ_MODEL,  # Correct parameter name\n",
        "                api_key=GROQ_API_KEY\n",
        "            ),\n",
        "            instructions=[\n",
        "                \"Route to 'web' ONLY for: current events, real-time data, general knowledge\",\n",
        "                \"Route to 'rag' for: technical queries, project details, Divya's personal information, learning roadmaps\",\n",
        "                \"Respond ONLY with lowercase 'web' or 'rag'\",\n",
        "                \"Example 1: 'latest AI trends' → 'web'\",\n",
        "                \"Example 2: 'Divya's career goals' → 'rag'\"\n",
        "            ],\n",
        "            show_tool_calls=False\n",
        "        )\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Error creating router agent: {str(e)}\")\n",
        "        raise\n",
        "\n",
        "# ========== MAIN ==========\n",
        "def main():\n",
        "    \"\"\"Main function to run the digital twin application.\"\"\"\n",
        "    user_id = \"user_001\"\n",
        "    twin = DigitalTwin(name=\"Divya B Gowda\")\n",
        "    vectorstore = None\n",
        "\n",
        "    try:\n",
        "        logger.info(\"🔍 Loading PDF knowledge base...\")\n",
        "        pdf_text = load_pdf_text()\n",
        "        vectorstore = create_vector_store(pdf_text)\n",
        "\n",
        "        # Test vector store with a sample query\n",
        "        test_query = \"What is the main topic of this document?\"\n",
        "        test_results = retrieve_context(vectorstore, test_query)\n",
        "        logger.info(f\"🔍 Vector store test complete with {len(test_results)} results\")\n",
        "\n",
        "        # Initialize agents\n",
        "        web_agent = create_web_agent()\n",
        "        router_agent = create_router_agent()\n",
        "\n",
        "        logger.info(\"\\n🤖 Divya's AI Twin Activated (RAG+Web) - Type 'exit' to quit\\n\")\n",
        "\n",
        "        # Main interaction loop\n",
        "        while True:\n",
        "            try:\n",
        "                query = input(\"You: \").strip()\n",
        "                if not query:\n",
        "                    logger.warning(\"Empty query received, please try again.\")\n",
        "                    continue\n",
        "\n",
        "                if query.lower() in [\"exit\", \"quit\"]:\n",
        "                    logger.info(\"👋 Goodbye!\")\n",
        "                    break\n",
        "\n",
        "                # Route the query\n",
        "                route_result = router_agent.run(query)\n",
        "                route = route_result.content.strip().lower()\n",
        "                logger.info(f\"🔧 Routing to: {route}\")\n",
        "\n",
        "                # Process based on routing decision\n",
        "                if route == \"rag\":\n",
        "                    context = retrieve_context(vectorstore, query)\n",
        "                    rag_agent = create_rag_agent(context)\n",
        "                    response_result = rag_agent.run(query)\n",
        "                    response = response_result.content\n",
        "                elif route == \"web\":\n",
        "                    response_result = web_agent.run(query)\n",
        "                    response = response_result.content\n",
        "                else:\n",
        "                    logger.warning(f\"Invalid routing result: {route}, defaulting to RAG\")\n",
        "                    context = retrieve_context(vectorstore, query)\n",
        "                    rag_agent = create_rag_agent(context)\n",
        "                    response_result = rag_agent.run(query)\n",
        "                    response = response_result.content\n",
        "\n",
        "                # Personalize and store response\n",
        "                twin.remember(user_id, {\"query\": query, \"response\": response})\n",
        "                print(twin.personalize_response(user_id, response) + \"\\n\")\n",
        "\n",
        "            except KeyboardInterrupt:\n",
        "                logger.info(\"Session interrupted by user. Exiting...\")\n",
        "                break\n",
        "            except Exception as e:\n",
        "                logger.error(f\"⚠️ Processing error: {str(e)}\")\n",
        "                print(f\"⚠️ Error processing your request: {str(e)}\\n\")\n",
        "\n",
        "    except FileNotFoundError as e:\n",
        "        logger.error(f\"File not found: {str(e)}\")\n",
        "        print(f\"❌ {str(e)}\")\n",
        "    except Exception as e:\n",
        "        logger.error(f\"⚠️ Critical error: {str(e)}\")\n",
        "        print(f\"⚠️ Critical error: {str(e)}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "id": "HtTLhdbtYPQ0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dBw58nJQrtiU",
        "outputId": "2508e735-e615-4b10-a2fb-bca88c6d1472"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Writing app.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile app.py\n",
        "\n",
        "import streamlit as st\n",
        "from phi.agent import Agent\n",
        "from phi.model.groq import Groq\n",
        "from phi.tools.duckduckgo import DuckDuckGo\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain_community.vectorstores import Chroma\n",
        "from langchain.embeddings import HuggingFaceEmbeddings\n",
        "import pymupdf as fitz\n",
        "import os\n",
        "\n",
        "# ========== CONFIG ==========\n",
        "groq_api_key = \"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\"\n",
        "PDF_FILENAME = \"/content/Divya_Profile_Complete.pdf\"\n",
        "PERSIST_DIR = \"chroma_db\"\n",
        "\n",
        "# ========== STREAMLIT UI SETUP ==========\n",
        "st.set_page_config(\n",
        "    page_title=\"Divya's AI Twin\",\n",
        "    page_icon=\"🤖\",\n",
        "    layout=\"centered\"\n",
        ")\n",
        "st.title(\"🧠 Divya's AI Twin Chatbot\")\n",
        "st.markdown(\"Experience AI-powered conversations with RAG and web search capabilities\")\n",
        "\n",
        "# ========== SESSION STATE INITIALIZATION ==========\n",
        "if \"messages\" not in st.session_state:\n",
        "    st.session_state.messages = []\n",
        "if \"vectorstore\" not in st.session_state:\n",
        "    st.session_state.vectorstore = None\n",
        "if \"agents_initialized\" not in st.session_state:\n",
        "    st.session_state.agents_initialized = False\n",
        "\n",
        "# ========== PDF PROCESSING ==========\n",
        "@st.cache_resource\n",
        "def initialize_system(pdf_path):\n",
        "    \"\"\"Initialize the RAG system with PDF content\"\"\"\n",
        "    try:\n",
        "        # Load and process PDF\n",
        "        doc = fitz.open(pdf_path)\n",
        "        pdf_text = \"\\n\".join([page.get_text() for page in doc])\n",
        "\n",
        "        # Create vector store\n",
        "        text_splitter = RecursiveCharacterTextSplitter(\n",
        "            chunk_size=500,\n",
        "            chunk_overlap=100\n",
        "        )\n",
        "        docs = text_splitter.create_documents([pdf_text])\n",
        "        embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
        "        vectorstore = Chroma.from_documents(\n",
        "            documents=docs,\n",
        "            embedding=embeddings,\n",
        "            persist_directory=PERSIST_DIR\n",
        "        )\n",
        "\n",
        "        return vectorstore\n",
        "    except Exception as e:\n",
        "        st.error(f\"Error initializing system: {str(e)}\")\n",
        "        st.stop()\n",
        "\n",
        "# ========== AGENT INITIALIZATION ==========\n",
        "def initialize_agents():\n",
        "    \"\"\"Create and cache agents\"\"\"\n",
        "    return {\n",
        "        \"web_agent\": Agent(\n",
        "            name=\"Web Agent\",\n",
        "            model=Groq(id=\"llama3-70b-8192\", api_key=groq_api_key),\n",
        "            tools=[DuckDuckGo()],\n",
        "            instructions=[\n",
        "                \"Act as Divya B Gowda\",\n",
        "                \"Use web search for current/unknown information\",\n",
        "                \"Keep responses concise (1-2 sentences)\",\n",
        "                \"Maintain professional yet friendly tone\"\n",
        "            ],\n",
        "            show_tool_calls=True,\n",
        "            markdown=True\n",
        "        ),\n",
        "        \"router_agent\": Agent(\n",
        "            name=\"Router Agent\",\n",
        "            model=Groq(id=\"llama3-70b-8192\", api_key=groq_api_key),\n",
        "            instructions=[\n",
        "                \"Route to 'web' for: current events, general knowledge, greetings\",\n",
        "                \"Route to 'rag' for: technical queries, PDF-specific questions\",\n",
        "                \"Respond only with 'web' or 'rag'\"\n",
        "            ],\n",
        "            show_tool_calls=False\n",
        "        )\n",
        "    }\n",
        "\n",
        "# ========== CHAT INTERFACE ==========\n",
        "def main():\n",
        "    # File upload section\n",
        "    with st.sidebar:\n",
        "        st.header(\"Configuration\")\n",
        "        uploaded_file = st.file_uploader(\n",
        "            \"Upload Knowledge Base (PDF)\",\n",
        "            type=\"pdf\",\n",
        "            help=\"Upload the PDF file containing domain-specific knowledge\"\n",
        "        )\n",
        "\n",
        "        if uploaded_file:\n",
        "            # Save uploaded file\n",
        "            with open(PDF_FILENAME, \"wb\") as f:\n",
        "                f.write(uploaded_file.getbuffer())\n",
        "\n",
        "            # Initialize system with new PDF\n",
        "            st.session_state.vectorstore = initialize_system(PDF_FILENAME)\n",
        "            st.session_state.agents_initialized = False\n",
        "            st.success(\"Knowledge base updated successfully!\")\n",
        "\n",
        "    # Check initialization status\n",
        "    if not st.session_state.vectorstore:\n",
        "        st.warning(\"Please upload a PDF file to initialize the system\")\n",
        "        return\n",
        "\n",
        "    # Initialize agents once\n",
        "    if not st.session_state.agents_initialized:\n",
        "        with st.spinner(\"Initializing AI agents...\"):\n",
        "            st.session_state.agents = initialize_agents()\n",
        "            st.session_state.agents_initialized = True\n",
        "\n",
        "    # Display chat messages\n",
        "    for message in st.session_state.messages:\n",
        "        with st.chat_message(message[\"role\"]):\n",
        "            st.markdown(message[\"content\"])\n",
        "\n",
        "    # Chat input\n",
        "    if prompt := st.chat_input(\"Ask me anything...\"):\n",
        "        try:\n",
        "            # Add user message to history\n",
        "            st.session_state.messages.append({\"role\": \"user\", \"content\": prompt})\n",
        "            with st.chat_message(\"user\"):\n",
        "                st.markdown(prompt)\n",
        "\n",
        "            # Route the query\n",
        "            with st.spinner(\"Analyzing query...\"):\n",
        "                route_result = st.session_state.agents[\"router_agent\"].run(prompt)\n",
        "                route = route_result.content.strip().lower()\n",
        "\n",
        "            # Get response\n",
        "            with st.spinner(\"Generating response...\"):\n",
        "                if route == \"rag\":\n",
        "                    # RAG response\n",
        "                    context = st.session_state.vectorstore.similarity_search(prompt, k=5)\n",
        "                    context_text = \"\\n---\\n\".join([doc.page_content for doc in context])\n",
        "                    rag_agent = Agent(\n",
        "                        name=\"RAG Agent\",\n",
        "                        model=Groq(id=\"llama3-70b-8192\", api_key=groq_api_key),\n",
        "                        instructions=[\n",
        "                            f\"Context:\\n{context_text}\",\n",
        "                            \"Answer strictly from provided context\",\n",
        "                            \"If unsure, state 'Not in knowledge base'\",\n",
        "                            \"Keep responses technical and concise\"\n",
        "                        ],\n",
        "                        show_tool_calls=False,\n",
        "                        markdown=True\n",
        "                    )\n",
        "                    response = rag_agent.run(prompt).content\n",
        "                else:\n",
        "                    # Web response\n",
        "                    response = st.session_state.agents[\"web_agent\"].run(prompt).content\n",
        "\n",
        "            # Add assistant response\n",
        "            st.session_state.messages.append({\"role\": \"assistant\", \"content\": response})\n",
        "            with st.chat_message(\"assistant\"):\n",
        "                st.markdown(response)\n",
        "\n",
        "        except Exception as e:\n",
        "            st.error(f\"Error processing request: {str(e)}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A6kTv_tkryW1",
        "outputId": "f8b51f0c-aa89-4341-e6de-f655a07b63d6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "35.197.1.224"
          ]
        }
      ],
      "source": [
        "## Run this First to get this passoword ##\n",
        "\n",
        "!curl https://loca.lt/mytunnelpassword\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JFr-UpCzry8l",
        "outputId": "8c7ff5dc-84af-4ca2-a8c2-9e3877fdf44f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1G\u001b[0K⠙\u001b[1G\u001b[0K⠹\u001b[1G\u001b[0K⠸\u001b[1G\u001b[0K⠼\u001b[1G\u001b[0K⠴\u001b[1G\u001b[0K⠦\u001b[1G\u001b[0K\u001b[1G\u001b[0JNeed to install the following packages:\n",
            "localtunnel@2.0.2\n",
            "Ok to proceed? (y) \u001b[20Gy\n",
            "\n",
            "\u001b[1G\u001b[0K⠙\u001b[1G\u001b[0K⠹\u001b[1G\u001b[0K⠸\u001b[1G\u001b[0K⠼\u001b[1G\u001b[0K⠴\u001b[1G\u001b[0K⠦\u001b[1G\u001b[0K⠧\u001b[1G\u001b[0K⠇\u001b[1G\u001b[0K⠏\u001b[1G\u001b[0K⠋\u001b[1G\u001b[0K⠙\u001b[1G\u001b[0K⠹\u001b[1G\u001b[0K⠸\u001b[1G\u001b[0K⠼\u001b[1G\u001b[0K⠴\u001b[1G\u001b[0K⠦\u001b[1G\u001b[0K⠧\u001b[1G\u001b[0K⠇\u001b[1G\u001b[0K⠏\u001b[1G\u001b[0K⠋\u001b[1G\u001b[0K⠙\u001b[1G\u001b[0K⠹\u001b[1G\u001b[0K⠸\u001b[1G\u001b[0K⠼\u001b[1G\u001b[0Kyour url is: https://eager-views-camp.loca.lt\n",
            "^C\n"
          ]
        }
      ],
      "source": [
        "# Run Streamlit app on port 8501\n",
        "!streamlit run app.py --server.port 8501 &>/content/logs.txt &\n",
        "\n",
        "# Expose the app using localtunnel on port 8501\n",
        "!npx localtunnel --port 8501\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "d3a2a70a0d144df4a58aff567a18a5d6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5d36bc91258b4e848c5870d40c5bb85b",
              "IPY_MODEL_2e7bd5ff30514562b770cbe76f269c93",
              "IPY_MODEL_fb1bc9d705da4d91bd3c412c96fa4e95"
            ],
            "layout": "IPY_MODEL_c40964cdd59e42a1afa9e138f7faf878"
          }
        },
        "5d36bc91258b4e848c5870d40c5bb85b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_175f7ea90fd0484a863761f6508d76cf",
            "placeholder": "​",
            "style": "IPY_MODEL_f5853ce3d75b4646895fa999de7fdb6a",
            "value": "modules.json: 100%"
          }
        },
        "2e7bd5ff30514562b770cbe76f269c93": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f1dea63b2ffb44d88c765f773b127634",
            "max": 349,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_79ee24ed406e4fef89505d966579f254",
            "value": 349
          }
        },
        "fb1bc9d705da4d91bd3c412c96fa4e95": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_50acb6f821e343dd8ce0470617b596d7",
            "placeholder": "​",
            "style": "IPY_MODEL_3ef7b965fa51409e87c25219d92ad727",
            "value": " 349/349 [00:00&lt;00:00, 25.6kB/s]"
          }
        },
        "c40964cdd59e42a1afa9e138f7faf878": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "175f7ea90fd0484a863761f6508d76cf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f5853ce3d75b4646895fa999de7fdb6a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f1dea63b2ffb44d88c765f773b127634": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "79ee24ed406e4fef89505d966579f254": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "50acb6f821e343dd8ce0470617b596d7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3ef7b965fa51409e87c25219d92ad727": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "64c6deb742f645959403574c93a2a6c6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d3dd2366af2a4c1d8ab3c5e173119b93",
              "IPY_MODEL_3ad9708c0ccf4abba5c84f772303619a",
              "IPY_MODEL_9990dcab105b47f7b893dfd5fdb21b53"
            ],
            "layout": "IPY_MODEL_139b0b9389c746cc808922ef30e73284"
          }
        },
        "d3dd2366af2a4c1d8ab3c5e173119b93": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5c52a9198d924c42bf6d27ca0c1ac382",
            "placeholder": "​",
            "style": "IPY_MODEL_9173e7101f874d3c9f92742369b9a289",
            "value": "config_sentence_transformers.json: 100%"
          }
        },
        "3ad9708c0ccf4abba5c84f772303619a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_20c0242d75f84fd2b21d9f1955fd8267",
            "max": 116,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_dafe3ff7d9e4411aba90b512af172abb",
            "value": 116
          }
        },
        "9990dcab105b47f7b893dfd5fdb21b53": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a34b3571276242c89e83f7e252525d45",
            "placeholder": "​",
            "style": "IPY_MODEL_1eac8b400c0443079efa6569cc01aa81",
            "value": " 116/116 [00:00&lt;00:00, 9.67kB/s]"
          }
        },
        "139b0b9389c746cc808922ef30e73284": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5c52a9198d924c42bf6d27ca0c1ac382": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9173e7101f874d3c9f92742369b9a289": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "20c0242d75f84fd2b21d9f1955fd8267": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dafe3ff7d9e4411aba90b512af172abb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a34b3571276242c89e83f7e252525d45": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1eac8b400c0443079efa6569cc01aa81": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1ac9859aecd94a6c83e8be48e59e8d4f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_990bb927a0d14a8eba27cff6c4285233",
              "IPY_MODEL_f5bd9682d7c447ad9e1c9fa1b1f8e434",
              "IPY_MODEL_d4bda4952c9a4059861a28b168bcba07"
            ],
            "layout": "IPY_MODEL_44bd995520d74efa9bee75309c6c4d0d"
          }
        },
        "990bb927a0d14a8eba27cff6c4285233": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7a24b5850e054d7f8893c25369a85985",
            "placeholder": "​",
            "style": "IPY_MODEL_e5808515dda84e1db04d964cc69c844a",
            "value": "README.md: 100%"
          }
        },
        "f5bd9682d7c447ad9e1c9fa1b1f8e434": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9ff0c00f36714b21a13fcde0000a9861",
            "max": 10454,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_573473762cd64dd6ad38c49896e600c1",
            "value": 10454
          }
        },
        "d4bda4952c9a4059861a28b168bcba07": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6a1cc28e3263456a8d5e76f73d3bfe3b",
            "placeholder": "​",
            "style": "IPY_MODEL_45dde094a58c43898d0d669211ddf7d1",
            "value": " 10.5k/10.5k [00:00&lt;00:00, 905kB/s]"
          }
        },
        "44bd995520d74efa9bee75309c6c4d0d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7a24b5850e054d7f8893c25369a85985": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e5808515dda84e1db04d964cc69c844a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9ff0c00f36714b21a13fcde0000a9861": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "573473762cd64dd6ad38c49896e600c1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6a1cc28e3263456a8d5e76f73d3bfe3b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "45dde094a58c43898d0d669211ddf7d1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2e2fc99a413346f7a1a54ca30ace076f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_034d41ed95cf485e8e2759eaf27aab3d",
              "IPY_MODEL_db983defb4bd41399d3eea38d44ecb7e",
              "IPY_MODEL_5920c6f9d1e040298bd747489c342a37"
            ],
            "layout": "IPY_MODEL_d63c654ece8d43348d959dc0fbaef8d2"
          }
        },
        "034d41ed95cf485e8e2759eaf27aab3d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c8cede9ea0f94bfbbd14006677848958",
            "placeholder": "​",
            "style": "IPY_MODEL_46203df1220a418eb8a60da786fd0594",
            "value": "sentence_bert_config.json: 100%"
          }
        },
        "db983defb4bd41399d3eea38d44ecb7e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d613af8cc0384c299ea0b8d2470cedb1",
            "max": 53,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_cb1300cdd8474e5c90734d8cfe04e20b",
            "value": 53
          }
        },
        "5920c6f9d1e040298bd747489c342a37": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3cfb439192074656b2c2cdf6a5a83196",
            "placeholder": "​",
            "style": "IPY_MODEL_246f2373970246a0a56b40948b08530f",
            "value": " 53.0/53.0 [00:00&lt;00:00, 2.91kB/s]"
          }
        },
        "d63c654ece8d43348d959dc0fbaef8d2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c8cede9ea0f94bfbbd14006677848958": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "46203df1220a418eb8a60da786fd0594": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d613af8cc0384c299ea0b8d2470cedb1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cb1300cdd8474e5c90734d8cfe04e20b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3cfb439192074656b2c2cdf6a5a83196": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "246f2373970246a0a56b40948b08530f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a9dd71bfb1794111aa76d19df8a0edc8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3d5b000c8fe04793a4ba5fc4fc8a5366",
              "IPY_MODEL_aecb85fd296a41f08414f5ae64796f2f",
              "IPY_MODEL_6d4bdfb1ee564fc7b9f70ef3ac3f935e"
            ],
            "layout": "IPY_MODEL_18ee6a5870cf429c9ec4df55ef6e3c7f"
          }
        },
        "3d5b000c8fe04793a4ba5fc4fc8a5366": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_73d2ca89a5924fd8805c6df16804dcf0",
            "placeholder": "​",
            "style": "IPY_MODEL_f162b391e9844a719606038d4a433bc9",
            "value": "config.json: 100%"
          }
        },
        "aecb85fd296a41f08414f5ae64796f2f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_667d66fdc52f43dc80cbcd4545bb26d0",
            "max": 612,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_751e438dce9343babd98f511f77dc316",
            "value": 612
          }
        },
        "6d4bdfb1ee564fc7b9f70ef3ac3f935e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f03264c95c0e4ae78f2b605f58f00660",
            "placeholder": "​",
            "style": "IPY_MODEL_d70e3d6765bb4bf0b182be877995328a",
            "value": " 612/612 [00:00&lt;00:00, 55.4kB/s]"
          }
        },
        "18ee6a5870cf429c9ec4df55ef6e3c7f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "73d2ca89a5924fd8805c6df16804dcf0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f162b391e9844a719606038d4a433bc9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "667d66fdc52f43dc80cbcd4545bb26d0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "751e438dce9343babd98f511f77dc316": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f03264c95c0e4ae78f2b605f58f00660": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d70e3d6765bb4bf0b182be877995328a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "725e65e253624c13ad6a8c39a3e9d68c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_09fcee3d010a4800ac89a47084c21801",
              "IPY_MODEL_1a696bb2695648b5a5a2f51861ac6324",
              "IPY_MODEL_ccf3b636f495451b822899b890042343"
            ],
            "layout": "IPY_MODEL_5c28ba7a17ae45b99692d04b50471ae0"
          }
        },
        "09fcee3d010a4800ac89a47084c21801": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_77b73c791bee4178aa47d0646a8aca80",
            "placeholder": "​",
            "style": "IPY_MODEL_a3731c95248540df9a2bd64cbe0b10b7",
            "value": "model.safetensors: 100%"
          }
        },
        "1a696bb2695648b5a5a2f51861ac6324": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f5681b220c19436484c3f47cfe082327",
            "max": 90868376,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2cfb99f4c78a441ebbe7ba4682ba677a",
            "value": 90868376
          }
        },
        "ccf3b636f495451b822899b890042343": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_eac6f38c6e7b46d9a8fa21bf4999330c",
            "placeholder": "​",
            "style": "IPY_MODEL_52bb1c1dda1a433181468cd2ea5bdd15",
            "value": " 90.9M/90.9M [00:00&lt;00:00, 136MB/s]"
          }
        },
        "5c28ba7a17ae45b99692d04b50471ae0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "77b73c791bee4178aa47d0646a8aca80": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a3731c95248540df9a2bd64cbe0b10b7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f5681b220c19436484c3f47cfe082327": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2cfb99f4c78a441ebbe7ba4682ba677a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "eac6f38c6e7b46d9a8fa21bf4999330c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "52bb1c1dda1a433181468cd2ea5bdd15": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "db6aef6e5eb64cd88c50065d1eefd992": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0013aec5d7bc40249967c9fb49796886",
              "IPY_MODEL_1f705bc7e93c4e249715c6107d61589e",
              "IPY_MODEL_5b0d7dcd406f41558510b16f634d262a"
            ],
            "layout": "IPY_MODEL_b50d6dfd295f403fad5fb94c8dde0793"
          }
        },
        "0013aec5d7bc40249967c9fb49796886": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_74ff80ba829945a29cbbbb539cf06358",
            "placeholder": "​",
            "style": "IPY_MODEL_92c9807214644c7c9ab9bb69ea3d9b74",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "1f705bc7e93c4e249715c6107d61589e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_28f8e768be504154a90a0d2d05d27561",
            "max": 350,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0b1c677e9dcc420493fa9a4d15f0a5c2",
            "value": 350
          }
        },
        "5b0d7dcd406f41558510b16f634d262a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5c1fd96d9f2a4fc1bfab7f024fe083e5",
            "placeholder": "​",
            "style": "IPY_MODEL_77360ad15d054c29ad498f00a1e4e763",
            "value": " 350/350 [00:00&lt;00:00, 33.0kB/s]"
          }
        },
        "b50d6dfd295f403fad5fb94c8dde0793": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "74ff80ba829945a29cbbbb539cf06358": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "92c9807214644c7c9ab9bb69ea3d9b74": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "28f8e768be504154a90a0d2d05d27561": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0b1c677e9dcc420493fa9a4d15f0a5c2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5c1fd96d9f2a4fc1bfab7f024fe083e5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "77360ad15d054c29ad498f00a1e4e763": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "62c113a612004237aaec3c8e6b1f66df": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_36a99a41b1f3430bbdcedfe87d6ec75a",
              "IPY_MODEL_7c45e294ba614e8688856c150861e75a",
              "IPY_MODEL_c892f360bc4340efbeeb746e1f3ed018"
            ],
            "layout": "IPY_MODEL_2b31bbd91c7d473b995e87beaf8f7024"
          }
        },
        "36a99a41b1f3430bbdcedfe87d6ec75a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_64232849f7934591bad692c980744ed1",
            "placeholder": "​",
            "style": "IPY_MODEL_fd7fd0aaf3be4f4392079c4bc63be3c6",
            "value": "vocab.txt: 100%"
          }
        },
        "7c45e294ba614e8688856c150861e75a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_952cc63857bb4764986554c8e0a45748",
            "max": 231508,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5e19b02531a54f688f7cd5ec4e913ade",
            "value": 231508
          }
        },
        "c892f360bc4340efbeeb746e1f3ed018": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1ec1384ebe8f4651835b118d423e2a38",
            "placeholder": "​",
            "style": "IPY_MODEL_bbe9283a2bd24d569c217dca1040162c",
            "value": " 232k/232k [00:00&lt;00:00, 5.13MB/s]"
          }
        },
        "2b31bbd91c7d473b995e87beaf8f7024": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "64232849f7934591bad692c980744ed1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fd7fd0aaf3be4f4392079c4bc63be3c6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "952cc63857bb4764986554c8e0a45748": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5e19b02531a54f688f7cd5ec4e913ade": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1ec1384ebe8f4651835b118d423e2a38": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bbe9283a2bd24d569c217dca1040162c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1a561a2327a44e3c83dc77c32f75740c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ab89004b05c2445ea6668ebd81d1dd5b",
              "IPY_MODEL_02b9f92fdabb48dfbdf8addb31cfabf1",
              "IPY_MODEL_dd17b0d6969e4393b11a185f1f6bee81"
            ],
            "layout": "IPY_MODEL_6c869c6c26a64215ad74b3d1db011d01"
          }
        },
        "ab89004b05c2445ea6668ebd81d1dd5b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_84ad83bcc643451ab858fb13e0623685",
            "placeholder": "​",
            "style": "IPY_MODEL_f3ff2b8cdc7f44d0b00de3d9769e45b6",
            "value": "tokenizer.json: 100%"
          }
        },
        "02b9f92fdabb48dfbdf8addb31cfabf1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b2f39fbb1b7f4c84ae53a7b5e9875e1f",
            "max": 466247,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e825e22188d4404abf41a6184628a5c9",
            "value": 466247
          }
        },
        "dd17b0d6969e4393b11a185f1f6bee81": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_402401baa61d4b64ad57c2dd9442ad3c",
            "placeholder": "​",
            "style": "IPY_MODEL_cc62e7bd591e49ccb561fc1defcceecf",
            "value": " 466k/466k [00:00&lt;00:00, 1.64MB/s]"
          }
        },
        "6c869c6c26a64215ad74b3d1db011d01": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "84ad83bcc643451ab858fb13e0623685": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f3ff2b8cdc7f44d0b00de3d9769e45b6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b2f39fbb1b7f4c84ae53a7b5e9875e1f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e825e22188d4404abf41a6184628a5c9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "402401baa61d4b64ad57c2dd9442ad3c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cc62e7bd591e49ccb561fc1defcceecf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8c005987480d490fae0edae639150754": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_fe4d1e2bd8744f84869c89533c0f207d",
              "IPY_MODEL_e51ec310d3b34d5c9ebc113d1bbc2ccf",
              "IPY_MODEL_89512d3c12484ba5b4e653ae12536fb3"
            ],
            "layout": "IPY_MODEL_73b50a92d3074e60a3a869518543bde0"
          }
        },
        "fe4d1e2bd8744f84869c89533c0f207d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3cb7977642544b65a9b4ae92d2c97636",
            "placeholder": "​",
            "style": "IPY_MODEL_708a0c6a54db41e881db21b7fd9b570f",
            "value": "special_tokens_map.json: 100%"
          }
        },
        "e51ec310d3b34d5c9ebc113d1bbc2ccf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_34201716a56640888fbfa866717c5a7a",
            "max": 112,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6e864e8472324f6ead29bb7269063298",
            "value": 112
          }
        },
        "89512d3c12484ba5b4e653ae12536fb3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_81ada964b1ab4d6390a97576f28e28eb",
            "placeholder": "​",
            "style": "IPY_MODEL_bfdfcfb80c5643848d618e0c63c7d36f",
            "value": " 112/112 [00:00&lt;00:00, 6.30kB/s]"
          }
        },
        "73b50a92d3074e60a3a869518543bde0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3cb7977642544b65a9b4ae92d2c97636": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "708a0c6a54db41e881db21b7fd9b570f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "34201716a56640888fbfa866717c5a7a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6e864e8472324f6ead29bb7269063298": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "81ada964b1ab4d6390a97576f28e28eb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bfdfcfb80c5643848d618e0c63c7d36f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9cd3644f814b4a4c8bdc0d77dc3a8241": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_66348d24995a4ba4aa30131fc9cbe4ca",
              "IPY_MODEL_3f3ef8a56e784f46b79767979c2fce0e",
              "IPY_MODEL_904d9490d2214e8385d15f92b7581ddf"
            ],
            "layout": "IPY_MODEL_9f90dadc8331445aae7d84976a534334"
          }
        },
        "66348d24995a4ba4aa30131fc9cbe4ca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b311dcd5ec904259aff6594564fe69da",
            "placeholder": "​",
            "style": "IPY_MODEL_372d22223f714656b6f07a148853b746",
            "value": "config.json: 100%"
          }
        },
        "3f3ef8a56e784f46b79767979c2fce0e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2fee4088ccaf48b29ab84ef48beb3fcf",
            "max": 190,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9dbca64e82104523a31e96c509062f2f",
            "value": 190
          }
        },
        "904d9490d2214e8385d15f92b7581ddf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c8c99e8ec75240ef943c4334e906d868",
            "placeholder": "​",
            "style": "IPY_MODEL_63c77d8a7b1547449525e6f156729a90",
            "value": " 190/190 [00:00&lt;00:00, 16.3kB/s]"
          }
        },
        "9f90dadc8331445aae7d84976a534334": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b311dcd5ec904259aff6594564fe69da": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "372d22223f714656b6f07a148853b746": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2fee4088ccaf48b29ab84ef48beb3fcf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9dbca64e82104523a31e96c509062f2f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c8c99e8ec75240ef943c4334e906d868": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "63c77d8a7b1547449525e6f156729a90": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}